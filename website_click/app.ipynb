{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common import exceptions\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.common import exceptions\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FILE_NAME = 'output.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = \"C:\\\\Users\\\\user\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "def get_text(url):\n",
    "    source_code_from_URL = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(source_code_from_URL, 'lxml', from_encoding='utf-8')\n",
    "    text = ''\n",
    "    for item in soup.find_all('div', id='realArtcContents'):\n",
    "        text = text + str(item.find_all(text=True))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    cleaned_text = re.sub(r\"[^ㄱ-ㅎㅏ-ㅣ가-힣\\.]+\", \" \", str(text))\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(url):\n",
    "    source_code_from_URL = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(source_code_from_URL, 'html.parser', from_encoding='utf-8')\n",
    "    text = soup.find('h3',class_='articleSubecjt')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nate_comment(url):\n",
    "    driver = webdriver.Chrome(wd)\n",
    "    url_nums = re.findall(\"\\d+\", url)\n",
    "    addr = 'http://comm.news.nate.com/Comment/ArticleComment/List?artc_sq='+url_nums[0]+'n'+url_nums[1] # 댓글창 주소\n",
    "    driver.get(addr)\n",
    "    pages = 2\n",
    "    try:\n",
    "        for i in range(5):\n",
    "            WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR,\"body > div.commentBox.reply_hide > div:nth-child(3) > div.paging_wrap > a:nth-child(\"+str(pages)+\")\"))).click()\n",
    "            time.sleep(2)\n",
    "            print(pages, end=\" \")\n",
    "            pages+=1\n",
    "    except exceptions.ElementNotVisibleException as e: # 페이지 끝\n",
    "        pass\n",
    "    except Exception as e: # 다른 예외 발생시 확인\n",
    "        print(e)\n",
    "    html = driver.page_source\n",
    "    dom = BeautifulSoup(html, \"lxml\")\n",
    "    # 댓글이 들어있는 페이지 전체 크롤링\n",
    "    comments_raw = dom.find_all('dd',{'class':'usertxt'})\n",
    "    # 댓글의 text만 뽑는다.\n",
    "    comments = [comment.text.strip() for comment in comments_raw]\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naver_comment(url):\n",
    "    wd = \"C:\\\\Users\\\\user\\\\Downloads\\\\chromedriver_win32\\\\chromedriver\"\n",
    "    driver = webdriver.Chrome(wd)\n",
    "    driver.get(url)\n",
    "    pages = 0\n",
    "    try:\n",
    "        while True:\n",
    "            WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR,\"#cbox_module > div > div.u_cbox_paginate > a\"))).click()\n",
    "            time.sleep(1.5)\n",
    "            print(pages, end=\" \")\n",
    "            pages+=1\n",
    "    except exceptions.ElementNotVisibleException as e: # 페이지 끝\n",
    "        pass\n",
    "    \n",
    "    except Exception as e: # 다른 예외 발생시 확인\n",
    "        print(e)\n",
    "    html = driver.page_source\n",
    "    dom = BeautifulSoup(html, \"lxml\")\n",
    "    # 댓글이 들어있는 페이지 전체 크롤링\n",
    "    comments_raw = dom.find_all(\"span\", {\"class\" : \"u_cbox_contents\"})\n",
    "    # 댓글의 text만 뽑는다.\n",
    "    comments = [comment.text for comment in comments_raw]\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 키워드 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "from krwordrank.sentence import summarize_with_sentences\n",
    "def keyword_word(text):#키워드 단어 추출\n",
    "    data = text.split('.')\n",
    "    keywords, sents = summarize_with_sentences(data, num_keywords=10, num_keysents=10)\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_sentence(url):#키워드 문장 추출\n",
    "    m_text = get_text(url)\n",
    "    r_text = clean_text(m_text)\n",
    "    data = r_text.split('.')\n",
    "    keywords, sents = summarize_with_sentences(data, num_keywords=10, num_keysents=10)\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from konlpy.tag import Okt  \n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_load(comments):\n",
    "    token_sent=[]\n",
    "    for comment in comments:\n",
    "        temp = okt.morphs(comment, stem=True)\n",
    "        token_sent.append(temp)\n",
    "    max_words = 35000\n",
    "    tokenizer = Tokenizer(num_words = max_words) # 상위 35,000개의 단어만 보존\n",
    "    tokenizer.fit_on_texts(token_sent) \n",
    "    token_sent = tokenizer.texts_to_sequences(token_sent)\n",
    "    word_to_index = tokenizer.word_index\n",
    "    vocab_size = len(word_to_index)+1\n",
    "    max_len = 124\n",
    "    X_data = pad_sequences(token_sent, maxlen=max_len)\n",
    "    model = load_model('model8n.h5')\n",
    "    predict = model.predict_classes(X_data)\n",
    "    a = [1 for _ in range(len(X_data))]\n",
    "    for i in range(len(X_data)):\n",
    "        if(predict[i] == 0):\n",
    "            a[i]=0\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 댓글 수치 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_pos(results):\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    for result in results:\n",
    "        if result == 0:\n",
    "            pos += 1\n",
    "        else:\n",
    "            neg += 1\n",
    "    result = pos / (pos + neg) * 100\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(results):\n",
    "    for result in results:\n",
    "        if result == 1:\n",
    "            result == 'bad comment'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 악플 개수 세기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(num): #count는 악플 개수, number은 악플 위치\n",
    "    count = 0\n",
    "    number = []\n",
    "    for i in range(1, len(num)):\n",
    "        if num[i] == 1:\n",
    "            count += 1\n",
    "            number.append(i)\n",
    "    return count, number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 악플 데이터 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "def de_comment(comments, number):\n",
    "    new = np.delete(comments, number)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 악플 데이터 남기기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count2(num): #count는 악플 개수, number은 악플 위치\n",
    "    number = []\n",
    "    for i in range(1, len(num)):\n",
    "        if num[i] == 0:\n",
    "            number.append(i)\n",
    "    return number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "def de_comment2(comments, number):\n",
    "    new = np.delete(comments, number)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 선플 데이터 넣기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 추가 train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "def train(comments, model_result):\n",
    "    comment_data = pd.DataFrame(comments)\n",
    "    comment_data.columns = ['comment']\n",
    "    in_result = np.insert(model_result, 0, 0)\n",
    "    de_result = np.delete(in_result,0)\n",
    "    de_data = pd.DataFrame(de_result)\n",
    "    de_data.columns = ['label']\n",
    "    df_new = pd.concat([de_data, comment_data], axis = 1)\n",
    "    X_data = df_new['comment']\n",
    "    y_data = df_new['label']\n",
    "    normalized_text = []\n",
    "    for string in X_data.tolist():\n",
    "        try:\n",
    "            tokens = re.sub(r\"[^ㄱ-ㅎㅏ-ㅣ가-힣]+\", \" \", string.lower())\n",
    "        except Exception as e:\n",
    "            break\n",
    "    normalized_text.append(tokens)\n",
    "    #df_new.comment = normalized_text\n",
    "    okt = Okt()\n",
    "    X_token=[]\n",
    "    for sentence in df_new['comment']:\n",
    "        temp_X = []\n",
    "        temp_X = okt.morphs(sentence, stem=True) # 토큰화\n",
    "        X_token.append(temp_X)\n",
    "    max_words = 10000\n",
    "    tokenizer = Tokenizer(num_words = max_words) # 상위 35,000개의 단어만 보존\n",
    "    tokenizer.fit_on_texts(X_token) \n",
    "    X_token = tokenizer.texts_to_sequences(X_token)\n",
    "    word_to_index = tokenizer.word_index\n",
    "    vocab_size = len(word_to_index) + 1\n",
    "    max_len = 124\n",
    "    X_data = pad_sequences(X_token, maxlen=max_len)\n",
    "    y_data = np.array(y_data).reshape(-1, 1)\n",
    "    model = load_model('model8n.h5')\n",
    "    history = model.fit(X_data, y_data, epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 플라스크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template\n",
    "from flask import request, send_file, url_for\n",
    "from wtforms import Form, TextAreaField, validators, SelectField\n",
    "import pickle\n",
    "import sqlite3\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "url = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArticleForm(Form):\n",
    "    site = SelectField('',choices=[(1,'NATE'),(2,'NAVER')])\n",
    "    articleurl = TextAreaField('',[validators.DataRequired()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/')\n",
    "def index():\n",
    "    form = ArticleForm()\n",
    "    return render_template('article_app.html', form=form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/title', methods = ['POST'])\n",
    "def article():\n",
    "    form = ArticleForm(request.form)\n",
    "    if request.method == 'POST' and form.validate():\n",
    "        global url\n",
    "        url = request.form['articleurl']\n",
    "        title = get_title(url)\n",
    "        r_title = clean_text(title)\n",
    "        m_text = get_text(url)\n",
    "        r_text = clean_text(m_text)\n",
    "        return render_template('title.html', title=r_title, content=r_text)\n",
    "    return render_template('article_app.html', form=form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/result')\n",
    "def review():\n",
    "    global url\n",
    "    cr_comment = nate_comment(url)\n",
    "    '''if site == 'NATE':\n",
    "        cr_comment = nate_comment(url)\n",
    "    elif site == 'NAVER':\n",
    "        cr_comment = naver_comment(url)'''\n",
    "    results = model_load(cr_comment)\n",
    "    cm_count, number = count(results)\n",
    "    new_comment = de_comment(cr_comment, number)\n",
    "    result = neg_pos(results) \n",
    "    return render_template('result.html', list2=new_comment, list4=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/bad_comment')\n",
    "def bad_comment():\n",
    "    global url\n",
    "    cr_comment = nate_comment(url)\n",
    "    '''if site == 'NATE':\n",
    "        cr_comment = nate_comment(url)\n",
    "    elif site == 'NAVER':\n",
    "        cr_comment = naver_comment(url)'''\n",
    "    results = model_load(cr_comment)\n",
    "    number = count2(results)\n",
    "    new_comment = de_comment2(cr_comment, number)\n",
    "    return render_template('bad_comment.html', list1 = new_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/no_train')\n",
    "def no_train():\n",
    "    return render_template('no_train.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/thanks')\n",
    "def feedback():\n",
    "    global url\n",
    "    cr_comment = nate_comment(url)\n",
    "    '''if site == 'NATE':\n",
    "        cr_comment = nate_comment(url)\n",
    "    elif site == 'NAVER':\n",
    "        cr_comment = naver_comment(url)'''\n",
    "    results = model_load(cr_comment)\n",
    "    train_check = train(cr_comment, results)\n",
    "    return render_template('thanks.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "* Serving Flask app \"__main__\" (lazy loading)\n * Environment: production\n   WARNING: This is a development server. Do not use it in a production deployment.\n   Use a production WSGI server instead.\n * Debug mode: off\n * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n127.0.0.1 - - [02/Apr/2020 07:36:36] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n127.0.0.1 - - [02/Apr/2020 07:36:36] \"\u001b[37mGET /static/reset.css HTTP/1.1\u001b[0m\" 200 -\n127.0.0.1 - - [02/Apr/2020 07:36:36] \"\u001b[37mGET /static/style.css HTTP/1.1\u001b[0m\" 200 -\n127.0.0.1 - - [02/Apr/2020 07:36:37] \"\u001b[33mGET /nate.png HTTP/1.1\u001b[0m\" 404 -\n127.0.0.1 - - [02/Apr/2020 07:36:37] \"\u001b[33mGET /naver.png HTTP/1.1\u001b[0m\" 404 -\n127.0.0.1 - - [02/Apr/2020 07:36:37] \"\u001b[33mGET /daum.png HTTP/1.1\u001b[0m\" 404 -\n127.0.0.1 - - [02/Apr/2020 07:36:38] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}