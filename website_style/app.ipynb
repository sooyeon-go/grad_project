{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common import exceptions\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.common import exceptions\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FILE_NAME = 'output.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = \"D:\\\\Users\\\\kimdu\\\\Desktop\\\\GRAD\\\\chromedriver.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "def get_text(url):\n",
    "    source_code_from_URL = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(source_code_from_URL, 'lxml', from_encoding='utf-8')\n",
    "    text = ''\n",
    "    for item in soup.find_all('div', id='articeBody'):\n",
    "        text = text + str(item.find_all(text=True))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    cleaned_text = re.sub(r\"[^ㄱ-ㅎㅏ-ㅣ가-힣\\.]+\", \" \", text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(url):\n",
    "    source_code_from_URL = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(source_code_from_URL, 'lxml', from_encoding='utf-8')\n",
    "    text = soup.select_one('h2.end_tit')\n",
    "    text_r = text.get_text()\n",
    "    return text_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comment(url):\n",
    "    wd = \"D:\\\\Users\\\\kimdu\\\\Desktop\\\\GRAD\\\\chromedriver.exe\"\n",
    "    driver = webdriver.Chrome(wd)\n",
    "    driver.get(url)\n",
    "    pages = 0\n",
    "    try:\n",
    "        while True:\n",
    "            WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR,\"#cbox_module > div > div.u_cbox_paginate > a\"))).click()\n",
    "            time.sleep(1.5)\n",
    "            print(pages, end=\" \")\n",
    "            pages+=1\n",
    "    except exceptions.ElementNotVisibleException as e: # 페이지 끝\n",
    "        pass\n",
    "    \n",
    "    except Exception as e: # 다른 예외 발생시 확인\n",
    "        print(e)\n",
    "    html = driver.page_source\n",
    "    dom = BeautifulSoup(html, \"lxml\")\n",
    "    # 댓글이 들어있는 페이지 전체 크롤링\n",
    "    comments_raw = dom.find_all(\"span\", {\"class\" : \"u_cbox_contents\"})\n",
    "    # 댓글의 text만 뽑는다.\n",
    "    comments = [comment.text for comment in comments_raw]\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 키워드 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from krwordrank.sentence import summarize_with_sentences\n",
    "def keyword_word(text):#키워드 단어 추출\n",
    "    data = text.split('.')\n",
    "    keywords, sents = summarize_with_sentences(data, num_keywords=10, num_keysents=10)\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_sentence(url):#키워드 문장 추출\n",
    "    m_text = get_text(url)\n",
    "    r_text = clean_text(m_text)\n",
    "    data = r_text.split('.')\n",
    "    keywords, sents = summarize_with_sentences(data, num_keywords=10, num_keysents=10)\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# from konlpy.tag import Okt  \n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_load(comments):\n",
    "    token_sent=[]\n",
    "    for comment in comments:\n",
    "        temp = okt.morphs(comment, stem=True)\n",
    "        token_sent.append(temp)\n",
    "    max_words = 35000\n",
    "    tokenizer = Tokenizer(num_words = max_words) # 상위 35,000개의 단어만 보존\n",
    "    tokenizer.fit_on_texts(token_sent) \n",
    "    token_sent = tokenizer.texts_to_sequences(token_sent)\n",
    "    word_to_index = tokenizer.word_index\n",
    "    vocab_size = len(word_to_index)+1\n",
    "    max_len = 124\n",
    "    X_data = pad_sequences(token_sent, maxlen=max_len)\n",
    "    model = load_model('model11.h5')\n",
    "    predict = model.predict_classes(X_data)\n",
    "    a = [1 for _ in range(len(X_data))]\n",
    "    for i in range(len(X_data)):\n",
    "        if(predict[i] == 0):\n",
    "            a[i]=0\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 플라스크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template\n",
    "from flask import request, send_file, url_for\n",
    "from wtforms import Form, TextAreaField, validators\n",
    "import pickle\n",
    "import sqlite3\n",
    "import os\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "url = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArticleForm(Form):\n",
    "    articleurl = TextAreaField('',[validators.DataRequired()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/')\n",
    "def index():\n",
    "    form = ArticleForm(request.form)\n",
    "    return render_template('article_app.html', form=form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/title', methods = ['POST'])\n",
    "def article():\n",
    "    form = ArticleForm(request.form)\n",
    "    if request.method == 'POST' and form.validate():\n",
    "        global url\n",
    "        url = request.form['articleurl']\n",
    "        title = get_title(url)\n",
    "        r_title = clean_text(title)\n",
    "        m_text = get_text(url)\n",
    "        r_text = clean_text(m_text)\n",
    "        return render_template('title.html', title=r_title, content=r_text)\n",
    "    return render_template('article_app.html', form=form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/result')\n",
    "def review():\n",
    "    global url_for\n",
    "    key_sentence = keyword_sentence(url)\n",
    "    cr_comment = comment(url)\n",
    "    result = model_load(cr_comment)\n",
    "    return render_template('result.html',list=key_sentence, list2=cr_comment, list3=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/thanks', methods = ['POST'])\n",
    "def feedback():\n",
    "    feedback = request.form['feedback_button']\n",
    "    return render_template('thanks.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "* Serving Flask app \"__main__\" (lazy loading)\n * Environment: production\n   WARNING: This is a development server. Do not use it in a production deployment.\n   Use a production WSGI server instead.\n * Debug mode: off\n * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n127.0.0.1 - - [10/Mar/2020 00:32:59] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n127.0.0.1 - - [10/Mar/2020 00:32:59] \"\u001b[37mGET /static/style.css HTTP/1.1\u001b[0m\" 200 -\n127.0.0.1 - - [10/Mar/2020 00:32:59] \"\u001b[37mGET /static/reset.css HTTP/1.1\u001b[0m\" 200 -\n"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}