{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common import exceptions\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "def get_text(url):\n",
    "    source_code_from_URL = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(source_code_from_URL, 'lxml', from_encoding='utf-8')\n",
    "    text = ''\n",
    "    for item in soup.find_all('div', id='realArtcomments'):\n",
    "        text = text + str(item.find_all(text=True))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "    cleaned_text = re.sub(r\"[^ã„±-ã…ã…-ã…£ê°€-í£\\.]+\", \" \", text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(url):\n",
    "    source_code_from_URL = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(source_code_from_URL, 'html.parser', from_encoding='utf-8')\n",
    "    text = soup.find_all(\"h3\", {\"class\": \"articleSubject\"})\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comment(url):\n",
    "    soup = BeautifulSoup(urllib.request.urlopen(url).read(), \"html.parser\") \n",
    "    comments = [] \n",
    "    for i in soup.find_all(\"dd\", class_=\"usertxt\"): \n",
    "        comments.append(i.get_text().strip(\"\\n\\t \"))\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' .ë‚¨ê¹Œë‚´ë¦¬ê¸° ì¢‹ì•„í•˜ëŠ” ì¹œêµ¬ë‘ì€ ì†ì ˆí•˜ê¸° .ë‚¨ì€ ë„ˆí•œí…Œ ìƒê°ë³´ë‹¤ ë³„ ê´€ì‹¬ì—†ìœ¼ë‹ˆê¹Œ í•˜ê³ ì‹¶ì€ëŒ€ë¡œ í•˜ë©°ì‚´ê¸° .ê·¸ëŸ° ì¡ë‹¤í•œ ìƒê°í•˜ì§€ë§ê³  ê³µë¶€í•˜ê¸° .ë‚¨ì€ ë‚¨ì´ë‹ˆ ë‚˜ë‘ ë¹„êµí•˜ì§€ë§ê¸° .ìê¸°ë¥¼ ê°ê´€ì ìœ¼ë¡œ íŒë‹¨í• ì¤„ ì•Œë©° ìê¸°ì˜ ë‹¨ì ë„ ë°›ì•„ë“œë¦¬ê¸°',\n",
       " '.',\n",
       " ' ë…„ìƒ ëª…íšŒì‚¬ ë¶€ì‚¬ì¥ì„. ì–µëŒ€ì—°ë´‰ì´ê³  í‚¤ ê³µë¶€ ë“± ìê²©ì¦ ê°œ í† ìµ ì ëŒ€ ë³´ìœ ì¬ì‚° ì–µ ì„¹íŒŒ ëª…ì„. í•œë²ˆì˜ ì‹¤íŒ¨ë„ í•´ ë³´ì§€ ì•Šì€ ì‚¬ëŒì€ í•œë²ˆì˜ ë„ì „ë„ í•´ ë³´ì§€ ì•Šì€ ì‚¬ëŒì´ë‹¤. ë‚´ê°€ ê°€ì¥ì¢‹ì•„í•˜ëŠ” ë§ì„. ë§¤ì¼ê°™ì´ ë¬´ì–¸ê°€ì— ë„ì „í•´ ë³´ì…ˆ. ë„ì „í•˜ëŠ” ìë§Œì´ ì„±ì·¨ì˜ ê¸°ì¨ì„ ëˆ„ë¦´ ìˆ˜ ìˆìŒ',\n",
       " 'ë‹´ë¶€í„´ ë„ì›Œì“°ê¸° ì¢€...',\n",
       " 'ìì¡´ê°ì€ ìì‹ ì´ ì™„ë²½í•´ì„œ ë†’ì•„ì§€ëŠ” ê²ƒë„ ë˜ëŠ” ì™„ë²½í•¨ì„ ê¸°ëŒ€í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ë¶€ì¡±í•œ ë¶€ë¶„ì´ ìˆìŒì—ë„ ìˆëŠ” ê·¸ëŒ€ë¡œ ê·¸ëŸ° ìì‹ ì—ê²Œ ë§Œì¡±í•˜ëŠ” ê²ë‹ˆë‹¤.',\n",
       " 'ëˆ„ì°¨ ëŒ“ê¸€ì„ ë‹¬ì§€ë§Œ ë°˜ë§ë¡œ ì“´ ê¸€ì€ ê·¸ë‹¥ ì½ì„ ê°€ì¹˜ë¥¼ ëª» ëŠë‚Œ. ìŒìŠ´ì²´ë„ ì•„ë‹ˆê³ ...ê¼°ëŒ€ìŠ¤ëŸ½ê² ì§€ë§Œ ê·¸ë˜ë„ ìµœì†Œí•œì˜ ì˜ˆì˜ëŠ” í•„ìš”í•˜ë‹¤ê³  ë´„.',\n",
       " 'ìŒ .. ë‚˜ë„ ì§„ì§œ ìì¡´ê°ë‚®ê±°ë“  ê·¼ë° ã„¹ã…‡ ìš´ë™ê¾¸ì¤€íˆ í•´ë´ ê¸°ë³¸ì ìœ¼ë¡œ ìì‹ ê°ì€ ìƒê¸°ëŠ”ê±°ê°™ì•„ ì–¼êµ´ì´ë‘ ëª¸ë§¤ë„ ë” ì´ë»ì§€ê³  ê· í˜•ìˆì–´ì§€ê³  ì˜·íƒœë„ ë‹¬ë¼ì§€ë‹ˆê¹Œ ë‚œ ê·¸ëŸ°ë°ì„œ ì™ ì§€ ì—¬ìœ ê°€ ìƒê¸°ë”ë¼ê³  ë•€í˜ë¦¬ë©´ì„œ ìš´ë™í•˜ë©´ ë§ˆìŒê°€ì§ë„ ë‹¬ë¼ì§€ëŠ”ê²Œ ëŠê»´ì €',\n",
       " 'ëŠ¥ë ¥ìˆëŠ” ë‚¨ì ë§Œë‚˜ë©´ ìì¡´ê° ì˜¬ë¼ê°',\n",
       " 'ì‚¬ë‘í•´ ìˆ˜ê³ í•´ì¨ ì–´ì œ ìˆ˜ê³ í–ˆë‹¤ëŠ” ì¸ì‚¬ê°€ ëŠ¦ì—ˆë‹¤ ã…œ ì–´ì œë³´ë‹¤ ë” ë‚˜ì€ ì˜¤ëŠ˜ì´ ë˜ê¸¸ ë°”ë„ê²Œ ë‹ˆê°€ ì„¸ìƒì—ì„œ ìµœê³ ì•¼ ì œì¼ ê·¸ë‹ˆê¹Œ í•˜ê³  ì‹¶ì€ ê±° ë‹¤ í•´',\n",
       " 'ë‚˜ë„ ìì¡´ê° ì¡°ì¹´ ë‚®ì•˜ëŠ”ë° í•­ìƒ ë‚¨ë“¤ì´ ë¹„êµí•˜ëŠ”ê±° ì•ˆë“¤ìœ¼ë ¤ê³  ë…¸ë ¥í•˜ê³  ì§„ì§œ ë‚˜ë‘ ê°€ê¹Œì´ ìˆëŠ” ì‚¬ëŒìˆì–ì•„ ë­ ë¶€ëª¨ë‹˜ì´ë¼ë˜ê°€ ë…„ì§€ê¸° ì ˆì¹œ ë“±.. ì§„ì§œ ë‚´ê°€ ë¶€ì¡±í•œê²Œ ë­”ì§€ ë¬¼ì–´ë´ì„œ ê·¸ê±¸ ì—†ì• ë ¤ê³  í–ˆë˜ê²ƒê°™ì•„',\n",
       " 'ë°©ì„ì„ ì¢€ ì—¬ëŸ¬ ê°œ ê¹”ì•„ ë´.',\n",
       " 'ìƒì²˜ë°›ì„ ë•Œë§ˆë‹¤ ë‚˜í•œí…Œ ì ˆëŒ€ì ì¸ ì‚¬ë‘ì„ ì£¼ëŠ” ê°€ì¡±ì„ ìƒê°í•˜ê¸°. ì¹œêµ¬ëŠ” ì‹œê°„ì´ ì§€ë‚˜ë©´ì„œ ë³€í•˜ì§€ë§Œ ê°€ì¡±ì€ í‰ìƒ ë‚´ í¸. ë‹ˆê°€ ë‚  ì‹«ì–´í•´ ì›… ìƒê´€ì—†ì–´ ì§‘ì—ê°€ë©´ ë‚  ì ˆëŒ€ì ìœ¼ë¡œ ì‚¬ë‘í•´ì£¼ëŠ” ê°€ì¡±ì´ ìˆì–´ ì €ëŠ” ê·¸ë˜ì„œ ëˆ„êµ¬ ìš•í• ë•Œ ì¹œêµ¬í•œí…Œ ì˜ ì•ˆ í•©ë‹ˆë‹¤ ì—„ë§ˆí•œí…Œ í•©ë‹ˆë‹¤ ã…‹ã…‹ã…‹ ë‚´ê°€ ë‹¹ë‹¹í•˜ë©´ ì‚¬ëŒë“¤ì´ ì ˆëŒ€ ë¬´ì‹œ ëª»í•©ë‹ˆë‹¤ ëˆˆì¹˜ë³´ì§€ ë§ˆì„¸ìš”. ë‹¹ë‹¹ì€ ì–´ë””ì„œ ì˜¤ëƒ. ë‚  ì ˆëŒ€ì ìœ¼ë¡œ ì‚¬ë‘í•´ì£¼ëŠ” ì‚¬ëŒë“¤ì˜ ì‚¬ë‘ì—ì„œ ì˜µë‹ˆë‹¤.',\n",
       " 'ì €ë„ ë˜‘ê°™ì€ ì„±ê²©ì´ì—ìš” ê¸€ ì½ìœ¼ë©´ì„œ ì œ ì–˜ê¸°ì¸ê°€ ì‹¶ì„ ì •ë„ë¡œ ë¹„ìŠ·í•œë°ìš” ìì¡´ê°ì€ ì‰½ê²Œ ë–¨ì–´ì§€ì§€ë§Œ íšŒë³µí•˜ëŠ”ê²Œ ì •ë§ ì–´ë ¤ì›Œìš” ì €ë„ ì•„ì§ ë…¸ë ¥ì¤‘ì´ì§€ë§Œ ìê¸° ìì‹ ì— ëŒ€í•´ ì •í™•íˆ ì•Œì•˜ìœ¼ë©´ ì¢‹ê² ì–´ìš” ëŠ˜ ë§ì¶”ë©´ì„œ ì‚´ì•„ì™€ì„œ ìì‹ ì´ ë¬´ì—‡ì„ ì¢‹ì•„í•˜ê³  ì‹«ì–´í•˜ëŠ”ì§€ ê´€ì‹¬ìˆëŠ”ê²Œ ë­”ì§€ ì•„ëŠ”ê²Œ ê°€ì¥ ì¤‘ìš”í•´ìš” ì‚¬ì—°ì ë¶„ì´ ì¢‹ì€ë¶„ì´ì…”ì„œ ë¶„ëª…íˆ ì¢‹ì€ì¹œêµ¬ë“¤ì´ ìˆì„ê±°ì—ìš” ìì‹ ê³¼ ì˜ ë§ê³  ë‚˜ë¼ëŠ” ì‚¬ëŒ ìì²´ë¥¼ ì¢‹ì•„í•˜ëŠ” ë¶„ê³¼ ì§€ë‚´ì„¸ìš” ê·¸ëŸ° ë¶„ë“¤ì€ ë†“ì¹˜ë©´ ì •ë§ í›„íšŒí•©ë‹ˆë‹¤ ê¼­ ì¡ìœ¼ì„¸ìš” ì œê°€ í‰ì†Œì— ë“£ë˜ ì¡°ì–¸ë“¤ ì¤‘ ë„ì›€ëœê²ƒë§Œ ë§ì”€ë“œë ¤ìš” í™”ì´íŒ… í•˜ì„¸ìš” í• ìˆ˜ìˆì–´ìš”',\n",
       " 'ë‚˜ëŠ” ë°¥ì„ ì°¸ ì˜ ë¨¹ëŠ”ë‹¤. ì‹ ë°œì„ ê°€ì§€ëŸ°íˆ ë²—ëŠ”ë‹¤.ì²˜ëŸ¼ ì •ë§ ì‚¬ì†Œí•œ ê²ƒë¶€í„° ë‹¤ ì¹­ì°¬í•´ì£¼ê¸°. ë‚¨ì´ ì•„ë‹ˆë¼ ì–´ì œì˜ ë‚˜ì™€ ë¹„êµí•˜ë©° ë‚˜ëŠ” ì–´ì œë³´ë‹¤ ê³µë¶€ë¥¼ ë¶„ ë” í–ˆë‹¤.ì²˜ëŸ¼ ìì‹ ì„ ë¿Œë“¯ì´ ì—¬ê¸°ê³  ì¹­ì°¬í•´ì£¼ê¸°. ì¹œêµ¬ì—ê²Œ ë„Œ ì˜ˆë¯¼í•´ ë¼ê³  ì‰½ê²Œ ë¶€ì •ì ì¸ ë§ë¡œ ìƒì²˜ì¤„ ìˆ˜ ì—†ë“¯ì´ ìì‹ ì—ê²Œë„ ë‚œ ì˜ˆë¯¼í•´ ê°€ ì•„ë‹Œ ë‚œ ì„¬ì„¸í•˜ê³  ê°ìˆ˜ì„±ì´ í’ë¶€í•´ë¼ê³  ê¸ì •ì ì¸ ë§ë¡œ ë°”ê¿”í•´ì£¼ê¸°. ë‚´ê°€ ì‚¬ë‘í•˜ëŠ” ì‚¬ëŒì´ ì¢‹ì•„í•˜ëŠ”ê²ƒ í•´ì£¼ê³  ì‹¶ë“¯ì´ ë‚´ê°€ ì¢‹ì•„í•˜ëŠ”ê²ƒ ë‚´ê°€ ì›í•˜ëŠ”ê²ƒ ë‚´ê°€ ë¨¹ê³ ì‹¶ê³  ê°€ê³ ì‹¶ê³  í•˜ê³ ì‹¶ì€ê²ƒë“± ë‚´ê°€ í–‰ë³µí•œ ê²ƒì— ê´€ì‹¬ê°–ê³  ì¤‘ìš”ì‹œ ì—¬ê¸°ë©° ê·¸ê²ƒë“¤ì„ í•´ì¤Œìœ¼ë¡œì¨ ë‚˜ë¥¼ í–‰ë³µí•˜ê²Œ í•´ì£¼ê¸°. ë‚´ê°€ ì‚¬ë‘í•˜ëŠ” ì‚¬ëŒ ì• ì™„ê²¬ ì—ê² ì´ìœë§ ë³„ ì‚¬ì†Œí•œê²ƒë„ ë‹¤ ì¹­ì°¬ ì¢‹ì•„í•˜ëŠ” ê²ƒ ë‹¤ í•´ì£¼ë“¯ì´ ë‚˜ë¥¼ ì‚¬ë‘í•´ì£¼ê³  ì¡´ì¤‘í•´ì£¼ì„¸ìš”..',\n",
       " 'ì¼ë‹¨ ë„ì›€ì´ ë˜ì—ˆë‹¤ë‹ˆ ì •ë§ë‹¤í–‰ì…ë‹ˆë‹¤. ì„±ê²©ì€ í™˜ê²½ì— ë”°ë¼ ë‹¬ë¼ì§€ê¸°ë„ í•˜ë‹ˆ ë„˜ ê±±ì • ì•ˆí–ˆìœ¼ë©´ í•´ìš”. ì‹¤ì€ ì €ë„ êµ‰ì¥íˆ ë¹„ìŠ·í•œ ì„±ê²©ì…ë‹ˆë‹¤. ì„±ê²©ì´ì—ˆë‹¤ê³  í•˜ëŠ”ê²Œ ë§ê² ë„¤ìš”. ì™„ë²½ì£¼ì˜ ì„±í–¥ì— ë§¤ìš° ì˜ˆë¯¼í•œ... ì‹¤ì€ ë‚´ê°€ ëª¨ë‘ë¥¼ ë”°ì‹œí‚¤ê³  ìˆëŠ”ë° ì•„ë¬´ë„ ëª¨ë¦„ ã…ã… ìƒëŒ€ë°©ì´ ë‹¨ì ì´ ì–´ëŠ ìˆœê°„ ë³´ì´ê³  ì£¼ì§€ë„ ì•Šê³  ë°›ì§€ë„ ì•Šê² ë‹¤ëŠ” ì•½ê°„ì€ ê°œì¸ì£¼ì˜ì ì¸ ì„±í–¥ë„ ìˆì£ . ë§ê·¸ëŒ€ë¡œ ìì¡´ê° ë¶€ì¡±ì—ì„œ ì˜¤ëŠ” ê²ƒë“¤ì´ ë§ë”ë¼êµ¬ìš”. ì¢…ì´ë¥¼ ë°˜ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ë‚˜ì˜ ì¥ì  ë‚˜ì˜ ë‹¨ì ì„ ê°ê° ì¼ì„ë•Œë„ ì•„ë§ˆ ë‹¨ì ì„ ë§ì´ ì“°ì‹œê²Œ ë ê²ë‹ˆë‹¤. ì‰½ê²Œ ë§í•´ ë‚˜ë¥¼ ì‚¬ë‘í•˜ëŠ”ê²Œ ë¨¼ì €ì…ë‹ˆë‹¤. ë‚˜ì—ê²Œ ì˜í•´ì£¼ëŠ”ê²ƒ ì¢‹ì€ê²ƒë„ ë¨¹ê²Œ í•´ì£¼ê³  ìš´ë™ë„ í•´ì£¼ë©° ë‚˜ë¥¼ ê±´ê°•í•˜ê²Œ í•˜ëŠ”ê²ƒ ë¶€í„°.. ê¹Šê²Œ íŒŒê³ ë“¤ë©´ ë‚˜ì˜ ì¡´ì¬ê°€ ì–¼ë§ˆë‚˜ ê·€í•œ ê²ƒì¸ì§€ì— ëŒ€í•œ ê²ƒ. í•œë²ˆë¿ì¸ ì‚¶ì— ë‚˜ëŠ” ì–´ë–¤ ì¡´ì¬ë¡œ ì‚´ì•„ê°€ëŠ”ì§€ì— ëŒ€í•œ ì„±ì°°ì´ ì •ë§ í•„ìš”í•©ë‹ˆë‹¤. í˜¼ì ìƒê°í•˜ê¸°ì—” ìƒê°ì´ ë§ì€ íƒ€ì…ì´ë¼ ë°¤ìƒˆ ìƒê°í•´ë„ ì˜ ëª¨ë¥´ì‹¤ê±°ì—ìš”. ì£¼ë³€ì— ë‚˜ë¥¼ ì¸ê°„ì ìœ¼ë¡œ ì¡´ì¤‘í•˜ê³  ì „ì ìœ¼ë¡œ ì§€ì§€í•˜ëŠ” ëˆ„êµ°ê°€ê°€ ìˆë‹¤ë©´ ë”ë”ìš± ë¹¨ë¦¬ ì¢‹ì•„ì§€ì‹¤ ê±°ë¼ê³  ë´…ë‹ˆë‹¤. ì‰½ê²Œ ì ‘ê·¼í•´ì„œ ì¹œí•œì²™ í•˜ëŠ” ì‚¬ëŒë“¤ ë¶„ë³„ì€ í•  ìˆ˜ ìˆì„ê±°ë¼ ë¯¿ê³ ìš”. ë­”ê°€ ë‹¬ë¼ì§€ê³  ì‹¶ê³  ë³€í™”í•˜ê³  ì‹¶ë‹¤ëŠ” ìƒê°ë§Œìœ¼ë¡œ ë‹˜ì€ ì¶©ë¶„íˆ ì§€ê¸ˆë³´ë‹¤ í›¨ì”¬ ë‚˜ì€ ì‚¬ëŒì´ ë ê±°ì—ìš”. ê¸°ëŒ€ë©ë‹ˆë‹¤. ê¸ì •ì ì¸ ë³€í™”ëŠ” ì¸ìƒì„ ìˆœë°©í–¥ìœ¼ë¡œ ì´ëŒì–´ ì£¼ëŠ”ê²ƒì€ í™•ì‹¤í•˜ë‹ˆê¹Œìš” ',\n",
       " 'ë„¤ì´íŠ¸íŒì— ì“°ì˜ë°ê¸° ì—†ëŠ”ê¸€ì€ ì½ì§€ë§ì–´ ë‚¨í˜ ì—¬í˜ ì°¨ë³„ ì—°ì˜ˆì¸ ë¹„íŒ ë“±ë“±',\n",
       " 'ìì¡´ê° ë†’ì´ëŠ”ë²•',\n",
       " 'ì“°ë‹ˆ ì•„ì§ ì–´ë¦¬ì§€ë§Œ ì‚¬ëŒì€ ì €ë§ˆë‹¤ íƒ€ê³ ë‚˜ëŠ” ì„±í–¥ì´ ìˆì–´. ë‚¨ê³¼ ë‹¤ë¥´ë‹¤ê³  ë‚´ê°€ í‹€ë¦°ê±´ ì•„ë‹ˆì•¼. ë‹¤ë§Œ íƒ€ê³ ë‚œ ë‚˜ì˜ ì„±í–¥ì€ ë‚˜ì˜ ì˜ëª»ì´ ì•„ë‹ˆë©° ë‚´ê°€ ë°›ì•„ë“¤ì—¬ì•¼ í•  ë¿ì´ì§€. í•˜ì§€ë§Œ ë‚´ê°€ ë°›ì•„ë“¤ì¸ê±°ì§€ ë‚¨ì—ê²Œë„ ì´ê²Œ ë‚˜ë‹ˆê¹Œ ë°›ì•„ë“¤ì—¬ ë¼ê³  í• ìˆœ ì—†ê² ì§€. ê·¸ë˜ì„œ ì¼ì¢…ì˜ ê°€ë©´ê°™ì€ ê²ƒì„ ì“°ê²Œë¼. ì–´ë¥¸ì´ ë˜ë©´ ì°¨ì°¨ ì•Œê²Œë ê±°ê³  ê·¸ê±´ ì–´ë¥¸ìŠ¤ëŸ½ë‹¤ ë¼ê³  ì¹­ì°¬ë°›ëŠ” ìˆœê°„ì´ ë°˜ë³µë˜ë©´ ë­”ì§€ ê¹¨ë‹«ê²Œ ë ê±°ì•¼. í•œê°€ì§€ ëª…ì‹¬í• ê²ƒì€ ì§€ë‚˜ì¹˜ê²Œ ì†”ì§í•˜ì§€ë§ê¸° ë§ˆì°¬ê°€ì§€ë¡œ ë‚¨ì—ê²Œë„ ê·¸ëŸ¬í• ê²ƒì„ ìš”êµ¬í•˜ì§€ ì•Šê¸° ë°”ë¼ì§€ì•Šê¸°... ë‚˜ì˜ ì‚¶ì´ ë‚˜ì˜ í•˜ë£¨ ê¸°ë¶„ì´ íƒ€ì¸ì— ì˜í•´ ê³¤ë‘ë°•ì§ˆ ì¹˜ê²Œë” í—ˆë½í•˜ì§€ ë§ê¸° ',\n",
       " 'í—¬ìŠ¤ ë“±ë¡í•´ë³´ëŠ”ê±´ ì–´ë–¨ê¹Œ ì‚´ë¹¼ê³  ê·¼ìœ¡ë¶™ëŠ” ìê¸°ìì‹ ì—ê²Œ ìì‹ ê° ë¿œë¿œ ',\n",
       " 'ë‚¨ê³¼ ë¹„êµ ì•ˆí•˜ë©´ ë©ë‹ˆë‹¤',\n",
       " 'ìì¡´ê° ë§ê·¸ëŒ€ë¡œ ë‚´ê°€ë‚˜ë¥¼ì¡´ì¤‘í•´ì£¼ëŠ”ê±°ì•¼ íƒ€ì¸ê³¼ ë‚˜ë¥¼ë¹„êµí•˜ì§€ë§ê³  ë‚˜ì™€íƒ€ì¸ì´ ë‹¤ë¦„ì„ì¸ì •í•˜ê³  ë‚´ê°€ ë‚˜ë¥¼ì‚¬ë‘í•˜ëŠ”ê±°ì§€']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = comment('https://pann.nate.com/talk/349711351')\n",
    "t = []\n",
    "for i in s:\n",
    "    t.append(clean_text(str(i)))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-24a30a64d138>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://news.nate.com/view/20200305n25115'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clean_text' is not defined"
     ]
    }
   ],
   "source": [
    "t = get_text('https://news.nate.com/view/20200305n25115')\n",
    "cl = clean_text(t)\n",
    "print(cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comment(url):\n",
    "    wd = \"C:\\\\Users\\\\user\\\\Downloads\\\\chromedriver_win32\\\\chromedriver\"\n",
    "    driver = webdriver.Chrome(wd)\n",
    "    driver.get(url)\n",
    "    pages = 0\n",
    "    try:\n",
    "        while True:\n",
    "            WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR,\"#cbox_module > div > div.u_cbox_paginate > a\"))).click()\n",
    "            time.sleep(1.5)\n",
    "            print(pages, end=\" \")\n",
    "            pages+=1\n",
    "    except exceptions.ElementNotVisibleException as e: # í˜ì´ì§€ ë\n",
    "        pass\n",
    "    \n",
    "    except Exception as e: # ë‹¤ë¥¸ ì˜ˆì™¸ ë°œìƒì‹œ í™•ì¸\n",
    "        print(e)\n",
    "    html = driver.page_source\n",
    "    dom = BeautifulSoup(html, \"lxml\")\n",
    "    # ëŒ“ê¸€ì´ ë“¤ì–´ìˆëŠ” í˜ì´ì§€ ì „ì²´ í¬ë¡¤ë§\n",
    "    comments_raw = dom.find_all(\"span\", {\"class\" : \"u_cbox_contents\"})\n",
    "    # ëŒ“ê¸€ì˜ textë§Œ ë½‘ëŠ”ë‹¤.\n",
    "    comments = [comment.text for comment in comments_raw]\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "p=comment('https://entertain.naver.com/read?oid=109&aid=0004166734')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ì˜ë¯¸ë¶€ì—¬ì—†ì´ ì›ƒê¸°ê¸°ë¡œëŠ” ë†€ë©´ë­í•˜ë‹ˆì—ì„œ ì˜¤ëŠ˜ì´ ì ¤ì›ƒê²¼ìŒã…‹ã…‹ì§€ì„ì§„ ì¡°ì„¸í˜¸ëƒ…ë‘ê³ ì„  ë¬¸ë‹«ê³ ë„ë§ì¹˜ëŠ”ê±° ìµœê³ ì˜ í‚¬ë§í¬ì¸íŠ¸ã…‹ã…‹ã…‹ã…‹',\n",
       " 'ìœ ëŠ í–‰ë³µí•´í•˜ëŠ”ê±° ë„˜ ë³´ê¸°ì¢‹ë„¤ìš”ã…ã…ã…',\n",
       " 'ì˜¤í”„ë‹ìœ¼ë¡œ ë½•ë½‘ë„¼ã…‹ã…‹ã…‹ã…‹ã…‹ê°œì›ƒê²¨',\n",
       " 'ìœ ëŠê°€ ê¸°ë»í•˜ë©´ ì¢‹ì•„ìš”ğŸ˜†ğŸ˜†ğŸ˜†ğŸ˜† í† í¬ë§Œìœ¼ë¡œë„ ì›ƒê¹€',\n",
       " 'ìœ ì¬ì„ ì €ë ‡ê²Œ ì¦ê±°ì›Œ ì£½ì„ ê±° ê°™ì€ ì–¼êµ´ë¡œ ë¯¸ì¹œë“¯ì´ ì›ƒëŠ” ê±° ê·¼ 5ë…„ ë§Œì— ì²˜ìŒ ë³´ëŠ” ë“¯. ë‚˜ë¨¸ì§€ ì…‹ ë³´ê³  ì›ƒëŠ” ê±´ë° ì˜¤íˆë ¤ ê·¸ ì…‹ì€ ë¤ë¤í•˜ê³  í˜¼ì ì›ƒê²¨ì„œ ë’¤ë¡œ ë„˜ì–´ê°€ë ¤ëŠ” ê²Œ ë„ˆë¬´ ì›ƒê²¨ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹',\n",
       " 'ìœ ì¬ì„ ë°©ì†¡ ì•„ë‹Œ ì§„ì§œì›ƒëŠ”ê²ƒê°™ì•„ ë³´ëŠ”ì‚¬ëŒë„ ì¡°ì•˜ì–´ìš”. ê·¸ë¦¬ê³  ì‹¤ì œë¡œë„ ì±…ë§ˆë‹ˆ ì½ëŠ”ë‹¤í•˜ë„¤ìš”..ê´œíˆ 1ì¸ìê°€ ì•„ë‹˜',\n",
       " 'ëŸ°ë‹ë§¨ì—ì„œ ìˆ˜ë…„ì„ë´¤ëŠ”ë°ë„ ê´‘ìˆ˜ë‚˜ì˜¤ë‹ˆê¹Œ ë­”ê°€ì‹ ì„ í•¨',\n",
       " 'ì†Œì¤‘í•œ ìš°ë¦¬ ì‚°ìŠ¬ì´ê°€ íƒ€ê³ ìˆì–´ìš” ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹',\n",
       " 'ì°¨íƒ€ê³  ì´ë™í• ë•Œ ì†Œì¤‘í•œ ìœ ì‚°ìŠ¬ì´ íƒ€ê³  ìˆìŠµë‹ˆë‹¤.ã…‹ã…‹íƒœí˜¸PDì˜ ìœ ëŠë‹˜ì— ëŒ€í•œ ì• ì • ë³´ì´ì§€ ì•ŠëŠ” ê³³ì—ë„ í˜ëŸ¬ ë„˜ì³ ë‹´ì£¼ë„ ë¬´ë„ ë³¸ë°© ì‚¬ìˆ˜~',\n",
       " 'ìœ ëŠ ì •ë§ ì¢‹ì•„í•˜ëŠ”ê²Œ ëˆˆì— ë³´ì´ë“œë¼ã…ã…ã…ã…']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from konlpy.tag import Okt  \n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.common import exceptions\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_load(comments):\n",
    "    token_sent=[]\n",
    "    for comment in comments:\n",
    "        temp = okt.morphs(comment, stem=True)\n",
    "        token_sent.append(temp)\n",
    "        max_words = 35000\n",
    "    tokenizer = Tokenizer(num_words = max_words) # ìƒìœ„ 35,000ê°œì˜ ë‹¨ì–´ë§Œ ë³´ì¡´\n",
    "    tokenizer.fit_on_texts(token_sent) \n",
    "    token_sent = tokenizer.texts_to_sequences(token_sent)\n",
    "    word_to_index = tokenizer.word_index\n",
    "    vocab_size = len(word_to_index)+1\n",
    "    max_len = 124\n",
    "    X_data = pad_sequences(token_sent, maxlen=max_len)\n",
    "    model = load_model('model11.h5')\n",
    "    predict = model.predict_classes(X_data)\n",
    "    for i in range(len(X_data)):\n",
    "        if(predict[i] == 0):\n",
    "            a=0\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_load(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(url):\n",
    "    source_code_from_URL = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(source_code_from_URL, 'lxml', from_encoding='utf-8')\n",
    "    text = ''\n",
    "    for item in soup.find_all('div', id='articeBody'):\n",
    "        text = text + str(item.find_all(text=True))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt=get_text('https://entertain.naver.com/read?oid=109&aid=0004166734')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    cleaned_text = re.sub(r\"[^ã„±-ã…ã…-ã…£ê°€-í£\\.]+\", \" \", text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = clean_text(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\t\\t\\t'ë†€ë©´ ë­í•˜ë‹ˆ' ìœ ì¬ì„, ì ˆì¹œâ™¥ï¸ë“¤ê³¼ ë‚¨ì‚°â†’ì„œì â†’ë°© íƒˆì¶œ..í¬ìƒíœ´ê°€ 'ë§Œë½'[ì¢…í•©]\\n\\t\\t\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_title(url):\n",
    "    source_code_from_URL = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(source_code_from_URL, 'lxml', from_encoding='utf-8')\n",
    "    text = soup.select_one('h2.end_tit')\n",
    "    text_r = text.get_text()\n",
    "    return text_r\n",
    "title = get_title('https://entertain.naver.com/read?oid=109&aid=0004166734')\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ë†€ë©´ ë­í•˜ë‹ˆ ìœ ì¬ì„ ì ˆì¹œ ë“¤ê³¼ ë‚¨ì‚° ì„œì  ë°© íƒˆì¶œ..í¬ìƒíœ´ê°€ ë§Œë½ ì¢…í•© '"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from krwordrank.sentence import summarize_with_sentences\n",
    "def keyword_sentence(url):#í‚¤ì›Œë“œ ë¬¸ì¥ ì¶”ì¶œ\n",
    "    m_text = get_text('https://entertain.naver.com/read?oid=109&aid=0004166734')\n",
    "    r_text = clean_text(m_text)\n",
    "    data = r_text.split('.')\n",
    "    keywords, sents = summarize_with_sentences(data, num_keywords=11, num_keysents=10)\n",
    "    keyword = list(keywords.keys())\n",
    "    return keyword[0], sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ë†€ë©´ ë­í•˜ë‹ˆ ë°©ì†¡í™”ë©´ ìº¡ì²˜ ê¹€ë³´ë¼ ê¸°ì ìœ ì¬ì„ ì§€ì„ì§„ ì´ê´‘ìˆ˜ ì¡°ì„¸í˜¸ê°€ í¬ìƒ íœ´ê°€ë¥¼ ì¦ê²¼ë‹¤',\n",
       " ' ì¡°ì„¸í˜¸ë„ ì „ë¬¸ì ìœ¼ë¡œ ì›ƒìŒì„ ë“œë¦°ë‹¤ ê³  ì†Œê°œí–ˆëŠ”ë° ìœ ì¬ì„ì´ ì „ë¬¸ì ì¸ ê±° ì¹˜ê³¤ ì¡°ê¸ˆ ì•„ì‰½ë‹¤ ê³  í•˜ì ì¡°ì„¸í˜¸ëŠ” ê·¼ê·¼ì´ ë°¥ ë²Œì–´ ë¨¹ê³  ì‚°ë‹¤ ê³  ë°›ì•„ì³¤ë‹¤',\n",
       " ' ì´ê´‘ìˆ˜ì˜ ì˜ê²¬ì— ë”°ë¼ ìœ ì¬ì„ì€ ë‚¨ì‚° ëˆê°€ìŠ¤ ì§‘ê¹Œì§€ ê±¸ì–´ ê°€ìê³  í–ˆë‹¤',\n",
       " ' ì´ì— ì¡°ì„¸í˜¸ëŠ” ìš°ë¦¬ê°€ ë§Œë§Œí•œ ê±°ë‹¤ ë¼ê³  ë§ì•„ì³ ì›ƒìŒì„ ì•ˆê²¼ë‹¤',\n",
       " ' ì¡°ì„¸í˜¸ì™€ ì´ê´‘ìˆ˜ë„ í‰ìƒì‹œì— ì˜¤ëŠ” ê±´ ì¢‹ì€ë° íœ´ê°€ì— ì—¬ê¸¸ ì˜¤ëƒ ê³  í–ˆë‹¤',\n",
       " ' ì•„ë‚´ì™€ ì•„ì´ì™€ í–‰ë³µì„ ìœ„í•´ ë‹¬ë ¤ë‚˜ê°€ê³  ìˆë‹¤ ê³  í–ˆê³  ì´ê´‘ìˆ˜ëŠ” ì €ëŠ” ê°œê·¸ë§¨ì€ ì•„ë‹ˆì§€ë§Œ ì£¼ë§ ì˜ˆëŠ¥ì„ í•˜ê³  ìˆë‹¤ ê³  ë§í•´ ì›ƒìŒì„ ì•ˆê²¼ë‹¤',\n",
       " ' ì„¸ ì‚¬ëŒì€ ìœ ì¬ì„ê³¼ ë‹¨ë‘˜ì´ ëŒ€ ë¡œ ë– ë‚˜ëŠ” ì—¬í–‰ì¸ ì¤„ ì•Œê³  ì™”ëŠ”ë° ì•Œê³  ë³´ë‹ˆ ì¸ì´ ë– ë‚˜ëŠ” ì—¬í–‰ì´ ëë‹¤',\n",
       " ' ìš°ë¦¬ ë„·ì´ ì–´ë”” ê°€ëŠ” ê±° ì²˜ìŒì´ë‹¤ ë¼ê³  ê¸°ë»í•˜ëŠ” ìœ ì¬ì„',\n",
       " ' ì§€ì„ì§„ì€ ì´ê²Œ ì´ í”„ë¡œê·¸ë¨ì˜ ìœ„ì—„ì´ë‹¤',\n",
       " ' ê±·ëŠ” ê±¸ ì¢‹ì•„í•œë‹¤ ë©° ì—¬í–‰í•˜ë©´ì„œ ì°¨ íƒ€ëŠ” ê²ƒë„ ì¢‹ì§€ë§Œ ê±¸ìœ¼ë©° ë³´ëŠ” ê±¸ ì¢‹ì•„í•œë‹¤ ê³  ë§í–ˆë‹¤']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword, sents = keyword_sentence(clean)\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ìº¡ì²˜'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(current_word, n): # ëª¨ë¸, í† í¬ë‚˜ì´ì €, í˜„ì¬ ë‹¨ì–´, ë°˜ë³µí•  íšŸìˆ˜\n",
    "    global keyword\n",
    "    model = load_model('model_create.h5')\n",
    "    max_words = 35000\n",
    "    t = Tokenizer(num_words = max_words)\n",
    "    init_word = current_word \n",
    "    sentence = ''\n",
    "    for _ in range(n): # në²ˆ ë°˜ë³µ\n",
    "        encoded = t.texts_to_sequences([current_word])[0] # í˜„ì¬ ë‹¨ì–´ì— ëŒ€í•œ ì •ìˆ˜ ì¸ì½”ë”©\n",
    "        encoded = pad_sequences([encoded], maxlen=30, padding='pre') # ë°ì´í„°ì— ëŒ€í•œ íŒ¨ë”©\n",
    "        result = model.predict_classes(encoded, verbose=0)\n",
    "    # ì…ë ¥í•œ X(í˜„ì¬ ë‹¨ì–´)ì— ëŒ€í•´ì„œ yë¥¼ ì˜ˆì¸¡í•˜ê³  y(ì˜ˆì¸¡í•œ ë‹¨ì–´)ë¥¼ resultì— ì €ì¥.\n",
    "        for k, index in t.word_index.items(): \n",
    "            if index == result: # ë§Œì•½ ì˜ˆì¸¡í•œ ë‹¨ì–´ì™€ ì¸ë±ìŠ¤ì™€ ë™ì¼í•œ ë‹¨ì–´ê°€ ìˆë‹¤ë©´\n",
    "                break # í•´ë‹¹ ë‹¨ì–´ê°€ ì˜ˆì¸¡ ë‹¨ì–´ì´ë¯€ë¡œ break\n",
    "        current_word = current_word + ' '  + k # í˜„ì¬ ë‹¨ì–´ + ' ' + ì˜ˆì¸¡ ë‹¨ì–´ë¥¼ í˜„ì¬ ë‹¨ì–´ë¡œ ë³€ê²½\n",
    "        sentence = sentence + ' ' + k # ì˜ˆì¸¡ ë‹¨ì–´ë¥¼ ë¬¸ì¥ì— ì €ì¥\n",
    "    # forë¬¸ì´ë¯€ë¡œ ì´ í–‰ë™ì„ ë‹¤ì‹œ ë°˜ë³µ\n",
    "    sentence = init_word + sentence\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "def clean_sentence(word):\n",
    "    global keyword\n",
    "    max_words = 35000\n",
    "    clean_sen = []\n",
    "    for i in range(0,10):\n",
    "        sentence = sentence_generation(word, i)\n",
    "        clean_sen.append(sentence)\n",
    "        i += 1\n",
    "    return clean_sen[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'k' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-8a187819ae4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclean_sentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-48-ba012d1d4d07>\u001b[0m in \u001b[0;36mclean_sentence\u001b[1;34m(word)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mclean_sen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0msentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msentence_generation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mclean_sen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-47-00ef959e2e49>\u001b[0m in \u001b[0;36msentence_generation\u001b[1;34m(current_word, n)\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# ë§Œì•½ ì˜ˆì¸¡í•œ ë‹¨ì–´ì™€ ì¸ë±ìŠ¤ì™€ ë™ì¼í•œ ë‹¨ì–´ê°€ ìˆë‹¤ë©´\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                 \u001b[1;32mbreak\u001b[0m \u001b[1;31m# í•´ë‹¹ ë‹¨ì–´ê°€ ì˜ˆì¸¡ ë‹¨ì–´ì´ë¯€ë¡œ break\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mcurrent_word\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_word\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' '\u001b[0m  \u001b[1;33m+\u001b[0m \u001b[0mk\u001b[0m \u001b[1;31m# í˜„ì¬ ë‹¨ì–´ + ' ' + ì˜ˆì¸¡ ë‹¨ì–´ë¥¼ í˜„ì¬ ë‹¨ì–´ë¡œ ë³€ê²½\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0msentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mk\u001b[0m \u001b[1;31m# ì˜ˆì¸¡ ë‹¨ì–´ë¥¼ ë¬¸ì¥ì— ì €ì¥\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# forë¬¸ì´ë¯€ë¡œ ì´ í–‰ë™ì„ ë‹¤ì‹œ ë°˜ë³µ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'k' referenced before assignment"
     ]
    }
   ],
   "source": [
    "clean_sentence(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(model, t, current_word, n): # ëª¨ë¸, í† í¬ë‚˜ì´ì €, í˜„ì¬ ë‹¨ì–´, ë°˜ë³µí•  íšŸìˆ˜\n",
    "    global word\n",
    "    init_word = current_word # ì²˜ìŒ ë“¤ì–´ì˜¨ ë‹¨ì–´ë„ ë§ˆì§€ë§‰ì— ê°™ì´ ì¶œë ¥í•˜ê¸°ìœ„í•´ ì €ì¥\n",
    "    sentence = ''\n",
    "    for _ in range(n): # në²ˆ ë°˜ë³µ\n",
    "        encoded = t.texts_to_sequences([current_word])[0] # í˜„ì¬ ë‹¨ì–´ì— ëŒ€í•œ ì •ìˆ˜ ì¸ì½”ë”©\n",
    "        encoded = pad_sequences([encoded], maxlen=30, padding='pre') # ë°ì´í„°ì— ëŒ€í•œ íŒ¨ë”©\n",
    "        result = model.predict_classes(encoded, verbose=0)# ì…ë ¥í•œ X(í˜„ì¬ ë‹¨ì–´)ì— ëŒ€í•´ì„œ yë¥¼ ì˜ˆì¸¡í•˜ê³  y(ì˜ˆì¸¡í•œ ë‹¨ì–´)ë¥¼ resultì— ì €ì¥.\n",
    "        for word, index in t.word_index.items(): \n",
    "            if index == result: # ë§Œì•½ ì˜ˆì¸¡í•œ ë‹¨ì–´ì™€ ì¸ë±ìŠ¤ì™€ ë™ì¼í•œ ë‹¨ì–´ê°€ ìˆë‹¤ë©´\n",
    "                break # í•´ë‹¹ ë‹¨ì–´ê°€ ì˜ˆì¸¡ ë‹¨ì–´ì´ë¯€ë¡œ break\n",
    "        current_word = current_word + ' '  + word # í˜„ì¬ ë‹¨ì–´ + ' ' + ì˜ˆì¸¡ ë‹¨ì–´ë¥¼ í˜„ì¬ ë‹¨ì–´ë¡œ ë³€ê²½\n",
    "        sentence = sentence + ' ' + word # ì˜ˆì¸¡ ë‹¨ì–´ë¥¼ ë¬¸ì¥ì— ì €ì¥\n",
    "    # forë¬¸ì´ë¯€ë¡œ ì´ í–‰ë™ì„ ë‹¤ì‹œ ë°˜ë³µ\n",
    "    sentence = init_word + sentence\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(word):\n",
    "    clean_sen = []\n",
    "    model = load_model('model_create.h5')\n",
    "    max_words = 35000\n",
    "    t = Tokenizer(num_words = max_words)\n",
    "    for i in range(0,10):\n",
    "        sentence = sentence_generation(model, t, word, i)\n",
    "        clean_sen.append(sentence)\n",
    "        i += 1\n",
    "    return clean_sen[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_sentence(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
