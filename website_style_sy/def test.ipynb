{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common import exceptions\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://news.nate.com/view/20200314n09669?mid=n1008'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "def get_text(url):\n",
    "    source_code_from_URL = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(source_code_from_URL, 'lxml', from_encoding='utf-8')\n",
    "    text = ''\n",
    "    for item in soup.find_all('div', id='realArtcContents'):\n",
    "        text = text + str(item.find_all(text=True))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    cleaned_text = re.sub(r\"[^ㄱ-ㅎㅏ-ㅣ가-힣\\.]+\", \" \", str(text))\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(url):\n",
    "    source_code_from_URL = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(source_code_from_URL, 'html.parser', from_encoding='utf-8')\n",
    "    text = soup.find('h3',class_='articleSubecjt')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = \"C:\\\\Users\\\\user\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comment(url):\n",
    "    driver = webdriver.Chrome(wd)\n",
    "    url_nums = re.findall(\"\\d+\", url)\n",
    "    addr = 'http://comm.news.nate.com/Comment/ArticleComment/List?artc_sq='+url_nums[0]+'n'+url_nums[1] # 댓글창 주소\n",
    "    driver.get(addr)\n",
    "    pages = 2\n",
    "    try:\n",
    "        for i in range(5):\n",
    "            WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR,\"body > div.commentBox.reply_hide > div:nth-child(3) > div.paging_wrap > a:nth-child(\"+str(pages)+\")\"))).click()\n",
    "            time.sleep(2)\n",
    "            print(pages, end=\" \")\n",
    "            pages+=1\n",
    "    except exceptions.ElementNotVisibleException as e: # 페이지 끝\n",
    "        pass\n",
    "    except Exception as e: # 다른 예외 발생시 확인\n",
    "        print(e)\n",
    "    html = driver.page_source\n",
    "    dom = BeautifulSoup(html, \"lxml\")\n",
    "    # 댓글이 들어있는 페이지 전체 크롤링\n",
    "    comments_raw = dom.find_all('dd',{'class':'usertxt'})\n",
    "    # 댓글의 text만 뽑는다.\n",
    "    comments = [comment.text.strip() for comment in comments_raw]\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3 4 5 6 "
     ]
    },
    {
     "data": {
      "text/plain": [
       "['유승호 외모 지적ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ\\n유승호가 80kg까지 나가도 강남 일대 씹어먹을텐데 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ',\n",
       " '내가 저얼굴이면 누가 외모지적해도 피식도 안할거같은데 맘이 여린가',\n",
       " '솔직히 급 노화...\\n아저씨 다됐음ㅋ',\n",
       " '너무 예민한것 아닌지.',\n",
       " '유승호를 외모로 까?ㅋㅋㅋ',\n",
       " '승호야ㅋㅋㅋㅋㅋㅋ 한귀로 듣고 흘릴 가치도 없다 걍 무시해ㅋㅋㅋ',\n",
       " '살찐것도 모르겠고 잘생기기만 했어',\n",
       " '어디가 살쪘다는건지 알수가 없네요? 훈남인데 별 악플이다있네요 드라마 잼있구 본방사수중이에요~^^',\n",
       " '유승호가 100kg여도 나보다는 잘생겼을거같은데;',\n",
       " '근데 유승호도 연기가 참안늘어  연기에 깊이가 없다고 할까?',\n",
       " '어디가 쪘다는 건지? 잘생겼는뎅~~',\n",
       " '아니 누가 누굴보고 외모 지적을해?\\n남자가 봐도 존잘인데 뭐지;;',\n",
       " '외모고 자시고 연기도 별로고 드라마가 너무 재미없더라ㅋㅋㅋ',\n",
       " '오징어들이 누구를 건드나',\n",
       " '우리나라에서 제일 잘생긴 배우 중 하나라 생각했는데 유승호도 외모악플이 신경쓰이는게 신기하다... 연기잔데 배역따라서 살 좀 찌울 수 있지',\n",
       " '악플러들 불러다가 같이 셀카찍어 인스타 올려라 승호야 ㅋㅋㅋ',\n",
       " '잘생겼구만  지적한사람면상보자',\n",
       " '유승호 내이상형 ㅠㅠ',\n",
       " '아니 유승호가 외모지적으로 까여?ㅋㅋㅋ  존잘이던데',\n",
       " '드라마 안보는데 유승호 때문에 메모리스트 봄. 어디가 살이찜? 진짜 소름끼칠 정도로 잘생겼던데.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = comment(url)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 톱스타뉴스 김효진 메모리스트 유승호가 외모 악플에 대한 심경을 고백한 후 인스타그램을 업데이트했다. 앞서 지난 일 유승호는 자신의 인스타스토리를 통해 경찰 역할이라 일부러 살 많이 찌웠어요. 저도 알아요 얼굴 살찐 거 라는 글을 남긴 바 있다. 일부 네티즌의 악플에 대다수의 네티즌은 잘생겼는데 어디가 찐거냐 며 이해가 안된다는 반응을 보였다. 자신의 글이 이슈가 되자 유승호는 결국 인스타스토리를 삭제했고 메모리스트 촬영 사진을 남기며 인스타그램 활동을 이어가고 있다. 일 오후 유승호는 자신의 인스타그램에 웃자 라는 글과 함께 사진 한 장을 게재했다. 공개된 사진 속에는 경찰 제복을 입고 메모리스트 를 촬영 중인 유승호의 모습이 담겨 있다. 특히 유승호의 환한 미소가 훈훈함을 자아낸다. 극중 유승호는 사이코메트리 초능력을 가진 형사이자 전 세계 유일무이 공인된 초능력자 동백 역을 맡아 열연 중에 있다. 한편 유승호 이세영 등이 출연 중인 메모리스트 는 매주 수 목요일 오후 시 분 방송된다. 김효진 . . 취재 및 보도 . . 톱스타뉴스 . . 무단전재 재배포 금지 대한민국 . 스타 사진뉴스 . 사진 을 클릭하면 국내 최대 사이즈인 사진을 볼 수 있습니다. 메모리스트 유승호 붉은 돼지 발견했다 재방송 넷플릭스 방영 여부는 메모리스트 유승호 검찰 허수아비 때려눕힌 맨손 액션 통쾌 직캠 유승호 년 올해는 유승호가 대세 유승호 외모 악플에 심경 고백 인스타 글 삭제 네티즌 무분별 비난 그만 지적 메모리스트 유승호 이세영 회 예고 공개 뜨거운 시청자 반응 . . . . . . . . . . . \n"
     ]
    }
   ],
   "source": [
    "t = get_text(url)\n",
    "cl = clean_text(t)\n",
    "print(cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from krwordrank.sentence import summarize_with_sentences\n",
    "def keyword_sentence(url):#키워드 문장 추출\n",
    "    m_text = get_text(url)\n",
    "    r_text = clean_text(m_text)\n",
    "    data = r_text.split('.')\n",
    "    keywords, sents = summarize_with_sentences(data, num_keywords=11, num_keysents=10)\n",
    "    keyword = list(keywords.keys())\n",
    "    return keyword[0], sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 자신의 글이 이슈가 되자 유승호는 결국 인스타스토리를 삭제했고 메모리스트 촬영 사진을 남기며 인스타그램 활동을 이어가고 있다',\n",
       " ' 앞서 지난 일 유승호는 자신의 인스타스토리를 통해 경찰 역할이라 일부러 살 많이 찌웠어요',\n",
       " ' 스타 사진뉴스 ',\n",
       " ' 저도 알아요 얼굴 살찐 거 라는 글을 남긴 바 있다',\n",
       " ' 일부 네티즌의 악플에 대다수의 네티즌은 잘생겼는데 어디가 찐거냐 며 이해가 안된다는 반응을 보였다',\n",
       " ' 김효진 ',\n",
       " ' ',\n",
       " ' 취재 및 보도 ',\n",
       " ' ',\n",
       " ' 톱스타뉴스 ']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword, sents = keyword_sentence(url)\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'유승호'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from konlpy.tag import Okt  \n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.common import exceptions\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_load(comments):\n",
    "    token_sent=[]\n",
    "    for comment in comments:\n",
    "        temp = okt.morphs(comment, stem=True)\n",
    "        token_sent.append(temp)\n",
    "        max_words = 35000\n",
    "    tokenizer = Tokenizer(num_words = max_words) # 상위 35,000개의 단어만 보존\n",
    "    tokenizer.fit_on_texts(token_sent) \n",
    "    token_sent = tokenizer.texts_to_sequences(token_sent)\n",
    "    word_to_index = tokenizer.word_index\n",
    "    vocab_size = len(word_to_index)+1\n",
    "    max_len = 124\n",
    "    X_data = pad_sequences(token_sent, maxlen=max_len)\n",
    "    model = load_model('model8n.h5')\n",
    "    predict = model.predict_classes(X_data)\n",
    "    #for i in range(len(X_data)):\n",
    "    #    if(predict[i] == 0):\n",
    "    #        a=0\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'유승호 외모 지적ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ\\n유승호가 80kg까지 나가도 강남 일대 씹어먹을텐데 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "내가 저얼굴이면 누가 외모지적해도 피식도 안할거같은데 맘이 여린가\n"
     ]
    }
   ],
   "source": [
    "print(s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result = model_load(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      "[0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model_result)\n",
    "print(np.delete(model_result,1))\n",
    "model_result.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "[2, 9, 11, 15, 16, 17, 18]\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "number = []\n",
    "for i in range(1,len(model_result)):\n",
    "    if model_result[i] == 1:\n",
    "        count += 1\n",
    "        number.append(i)\n",
    "print(count)\n",
    "print(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(num):\n",
    "    count = 0\n",
    "    number = []\n",
    "    for i in range(1, len(num)):\n",
    "        if num[i] == 1:\n",
    "            count += 1\n",
    "            number.append(i)\n",
    "    return count, number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "[2, 9, 11, 15, 16, 17, 18]\n"
     ]
    }
   ],
   "source": [
    "a,b = count(model_result)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete(result, number):\n",
    "    new = np.delete(result, number)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def de_comment(comments, number):\n",
    "    new = np.delete(comments, number)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['유승호 외모 지적ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ\\n유승호가 80kg까지 나가도 강남 일대 씹어먹을텐데 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ'\n",
      " '내가 저얼굴이면 누가 외모지적해도 피식도 안할거같은데 맘이 여린가' '너무 예민한것 아닌지.' '유승호를 외모로 까?ㅋㅋㅋ'\n",
      " '승호야ㅋㅋㅋㅋㅋㅋ 한귀로 듣고 흘릴 가치도 없다 걍 무시해ㅋㅋㅋ' '살찐것도 모르겠고 잘생기기만 했어'\n",
      " '어디가 살쪘다는건지 알수가 없네요? 훈남인데 별 악플이다있네요 드라마 잼있구 본방사수중이에요~^^'\n",
      " '유승호가 100kg여도 나보다는 잘생겼을거같은데;' '어디가 쪘다는 건지? 잘생겼는뎅~~'\n",
      " '외모고 자시고 연기도 별로고 드라마가 너무 재미없더라ㅋㅋㅋ' '오징어들이 누구를 건드나'\n",
      " '우리나라에서 제일 잘생긴 배우 중 하나라 생각했는데 유승호도 외모악플이 신경쓰이는게 신기하다... 연기잔데 배역따라서 살 좀 찌울 수 있지'\n",
      " '드라마 안보는데 유승호 때문에 메모리스트 봄. 어디가 살이찜? 진짜 소름끼칠 정도로 잘생겼던데.']\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "stra = de_comment(s, b)\n",
    "stra_num = delete(model_result, b)\n",
    "print(stra)\n",
    "print(stra_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>저런 이목구비 찾아봐.. 없어..  유승호 잘생겼으니까 헛소리 하지들 말자</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>외모 지적은 류준열이나 김제동같은애들이나 받는거지</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>삼성 이재용 재산걱정하는소리같은소리하고있네\\n씅질나게</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>찐것도 모르겠는데 그냥 너무 잘생겼어 우리 승호</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>외모는 문제가 없어 작품 고르는 안목이 문제인거지</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>하나 분명히 말하는 거지만 실제로 진짜 남자들은 살찌면 어, 살쪘네? 하고 말지 남...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>어떻게 저얼굴을...지적해...니들아빠가 원빈급이면..조금이해는해볼게..사진좀......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>유승호에게 외모악플이란 이재용 재산걱정해주는것과 같음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>세상에, 너무 말라서 좀 쪘으면 했는데 살쪘다라니. 유승호 배우님 언제나 응원합니다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>난 지금 모습 좋은데..원래 아역배우들 슬럼프 못이기는데.. 유승호는 아역배우 이미...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>요즘 경찰 방송쪽에 돈 엄청 쏟는가보네?\\n무슨 경찰 소재 드라마가 이리 막 쏟아지냐??</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>유승호가 아무리 쪄도 악플 단 새끼 니보단 훨씬 잘생겼다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>유승호 넘조타 하악~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>20 30대의 한국 남자들은 유승호에게 관심도 없거니와\\n악플 다는 것조차 귀찮아\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>진짜 제목만봐도 코웃음난다 유승호가 얼굴로 까이다닠ㅋㅋㅋ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>유승호 20ㅐ대 배우중에 외모 탑급인데ㅋㅋㅋ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>ㅋㅋㅋ 유승호는 건들지말자</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>한녀들 왜저래?\\n적당히좀 해라</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>이놈의 악플러드 전부 벌금형이상으로 형량을높여야 없어지려나.........</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>유승호한테 외모지적이라니 ㅋㅋㅋ ㅁㅊㄴ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              comment\n",
       "0           저런 이목구비 찾아봐.. 없어..  유승호 잘생겼으니까 헛소리 하지들 말자\n",
       "1                         외모 지적은 류준열이나 김제동같은애들이나 받는거지\n",
       "2                       삼성 이재용 재산걱정하는소리같은소리하고있네\\n씅질나게\n",
       "3                          찐것도 모르겠는데 그냥 너무 잘생겼어 우리 승호\n",
       "4                         외모는 문제가 없어 작품 고르는 안목이 문제인거지\n",
       "5   하나 분명히 말하는 거지만 실제로 진짜 남자들은 살찌면 어, 살쪘네? 하고 말지 남...\n",
       "6   어떻게 저얼굴을...지적해...니들아빠가 원빈급이면..조금이해는해볼게..사진좀......\n",
       "7                       유승호에게 외모악플이란 이재용 재산걱정해주는것과 같음\n",
       "8   세상에, 너무 말라서 좀 쪘으면 했는데 살쪘다라니. 유승호 배우님 언제나 응원합니다...\n",
       "9   난 지금 모습 좋은데..원래 아역배우들 슬럼프 못이기는데.. 유승호는 아역배우 이미...\n",
       "10  요즘 경찰 방송쪽에 돈 엄청 쏟는가보네?\\n무슨 경찰 소재 드라마가 이리 막 쏟아지냐??\n",
       "11                    유승호가 아무리 쪄도 악플 단 새끼 니보단 훨씬 잘생겼다\n",
       "12                                        유승호 넘조타 하악~\n",
       "13  20 30대의 한국 남자들은 유승호에게 관심도 없거니와\\n악플 다는 것조차 귀찮아\\...\n",
       "14                    진짜 제목만봐도 코웃음난다 유승호가 얼굴로 까이다닠ㅋㅋㅋ\n",
       "15                           유승호 20ㅐ대 배우중에 외모 탑급인데ㅋㅋㅋ\n",
       "16                                     ㅋㅋㅋ 유승호는 건들지말자\n",
       "17                                  한녀들 왜저래?\\n적당히좀 해라\n",
       "18          이놈의 악플러드 전부 벌금형이상으로 형량을높여야 없어지려나.........\n",
       "19                              유승호한테 외모지적이라니 ㅋㅋㅋ ㅁㅊㄴ"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "comment_data = pd.DataFrame(s)\n",
    "comment_data.columns = ['comment']\n",
    "comment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "in_result = np.insert(model_result, 0, 0)\n",
    "de_result = np.delete(in_result,0)\n",
    "print(de_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label\n",
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       1\n",
       "4       0\n",
       "5       0\n",
       "6       1\n",
       "7       0\n",
       "8       0\n",
       "9       1\n",
       "10      0\n",
       "11      1\n",
       "12      0\n",
       "13      0\n",
       "14      0\n",
       "15      1\n",
       "16      0\n",
       "17      1\n",
       "18      1\n",
       "19      0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_data = pd.DataFrame(de_result)\n",
    "de_data.columns = ['label']\n",
    "de_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>저런 이목구비 찾아봐.. 없어..  유승호 잘생겼으니까 헛소리 하지들 말자</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>외모 지적은 류준열이나 김제동같은애들이나 받는거지</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>삼성 이재용 재산걱정하는소리같은소리하고있네\\n씅질나게</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>찐것도 모르겠는데 그냥 너무 잘생겼어 우리 승호</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>외모는 문제가 없어 작품 고르는 안목이 문제인거지</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>하나 분명히 말하는 거지만 실제로 진짜 남자들은 살찌면 어, 살쪘네? 하고 말지 남...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>어떻게 저얼굴을...지적해...니들아빠가 원빈급이면..조금이해는해볼게..사진좀......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>유승호에게 외모악플이란 이재용 재산걱정해주는것과 같음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>세상에, 너무 말라서 좀 쪘으면 했는데 살쪘다라니. 유승호 배우님 언제나 응원합니다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>난 지금 모습 좋은데..원래 아역배우들 슬럼프 못이기는데.. 유승호는 아역배우 이미...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>요즘 경찰 방송쪽에 돈 엄청 쏟는가보네?\\n무슨 경찰 소재 드라마가 이리 막 쏟아지냐??</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>유승호가 아무리 쪄도 악플 단 새끼 니보단 훨씬 잘생겼다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>유승호 넘조타 하악~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>20 30대의 한국 남자들은 유승호에게 관심도 없거니와\\n악플 다는 것조차 귀찮아\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>진짜 제목만봐도 코웃음난다 유승호가 얼굴로 까이다닠ㅋㅋㅋ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>유승호 20ㅐ대 배우중에 외모 탑급인데ㅋㅋㅋ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>ㅋㅋㅋ 유승호는 건들지말자</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>한녀들 왜저래?\\n적당히좀 해라</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>이놈의 악플러드 전부 벌금형이상으로 형량을높여야 없어지려나.........</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>유승호한테 외모지적이라니 ㅋㅋㅋ ㅁㅊㄴ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                            comment\n",
       "0       0          저런 이목구비 찾아봐.. 없어..  유승호 잘생겼으니까 헛소리 하지들 말자\n",
       "1       0                        외모 지적은 류준열이나 김제동같은애들이나 받는거지\n",
       "2       0                      삼성 이재용 재산걱정하는소리같은소리하고있네\\n씅질나게\n",
       "3       1                         찐것도 모르겠는데 그냥 너무 잘생겼어 우리 승호\n",
       "4       0                        외모는 문제가 없어 작품 고르는 안목이 문제인거지\n",
       "5       0  하나 분명히 말하는 거지만 실제로 진짜 남자들은 살찌면 어, 살쪘네? 하고 말지 남...\n",
       "6       1  어떻게 저얼굴을...지적해...니들아빠가 원빈급이면..조금이해는해볼게..사진좀......\n",
       "7       0                      유승호에게 외모악플이란 이재용 재산걱정해주는것과 같음\n",
       "8       0  세상에, 너무 말라서 좀 쪘으면 했는데 살쪘다라니. 유승호 배우님 언제나 응원합니다...\n",
       "9       1  난 지금 모습 좋은데..원래 아역배우들 슬럼프 못이기는데.. 유승호는 아역배우 이미...\n",
       "10      0  요즘 경찰 방송쪽에 돈 엄청 쏟는가보네?\\n무슨 경찰 소재 드라마가 이리 막 쏟아지냐??\n",
       "11      1                    유승호가 아무리 쪄도 악플 단 새끼 니보단 훨씬 잘생겼다\n",
       "12      0                                        유승호 넘조타 하악~\n",
       "13      0  20 30대의 한국 남자들은 유승호에게 관심도 없거니와\\n악플 다는 것조차 귀찮아\\...\n",
       "14      0                    진짜 제목만봐도 코웃음난다 유승호가 얼굴로 까이다닠ㅋㅋㅋ\n",
       "15      1                           유승호 20ㅐ대 배우중에 외모 탑급인데ㅋㅋㅋ\n",
       "16      0                                     ㅋㅋㅋ 유승호는 건들지말자\n",
       "17      1                                  한녀들 왜저래?\\n적당히좀 해라\n",
       "18      1          이놈의 악플러드 전부 벌금형이상으로 형량을높여야 없어지려나.........\n",
       "19      0                              유승호한테 외모지적이라니 ㅋㅋㅋ ㅁㅊㄴ"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = pd.concat([de_data, comment_data], axis = 1)\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = df_new['comment']\n",
    "y_data = df_new['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['저런 이목구비 찾아봐 없어 유승호 잘생겼으니까 헛소리 하지들 말자', '외모 지적은 류준열이나 김제동같은애들이나 받는거지', '삼성 이재용 재산걱정하는소리같은소리하고있네 씅질나게', '찐것도 모르겠는데 그냥 너무 잘생겼어 우리 승호', '외모는 문제가 없어 작품 고르는 안목이 문제인거지']\n"
     ]
    }
   ],
   "source": [
    "normalized_text = []\n",
    "for string in X_data.tolist():\n",
    "    try:\n",
    "        tokens = re.sub(r\"[^ㄱ-ㅎㅏ-ㅣ가-힣]+\", \" \", string.lower())\n",
    "    except Exception as e:\n",
    "        print(string)\n",
    "        break\n",
    "    normalized_text.append(tokens)\n",
    "print(normalized_text[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저런 이목구비 찾아봐 없어 유승호 잘생겼으니까 헛소리 하지들 말자\n",
      "외모 지적은 류준열이나 김제동같은애들이나 받는거지\n",
      "삼성 이재용 재산걱정하는소리같은소리하고있네 씅질나게\n",
      "찐것도 모르겠는데 그냥 너무 잘생겼어 우리 승호\n",
      "외모는 문제가 없어 작품 고르는 안목이 문제인거지\n",
      "하나 분명히 말하는 거지만 실제로 진짜 남자들은 살찌면 어 살쪘네 하고 말지 남의 까지 쳐들어가서 아가리 털진 않습니다 외모가지고 굳이 쳐들어갈정도로 시간을 투자할 사람들은 아니거든요 다른 이유면 모를까 근데 외모가지고 그정도로 집착하는거면 일베같은거 하는 찐따들이지 여자들도 진성 찐따나 트위터하는 페미찐따가 아니면 굳이 찾아가진 않으니까 근데 제일 무서운 찐따가 여자찐따인게 문제지 구하라 설리만 봐도 \n",
      "어떻게 저얼굴을 지적해 니들아빠가 원빈급이면 조금이해는해볼게 사진좀 멀해도 예쁜승호 상처받지않길 \n",
      "유승호에게 외모악플이란 이재용 재산걱정해주는것과 같음\n",
      "세상에 너무 말라서 좀 쪘으면 했는데 살쪘다라니 유승호 배우님 언제나 응원합니다 잘생겨서 좋더만 무슨 \n",
      "난 지금 모습 좋은데 원래 아역배우들 슬럼프 못이기는데 유승호는 아역배우 이미지 벗은것 같아 좋아요 그전에 했던 영화도 괜찮았고요 난 봉이 김선달부터 그사람의 배역에 충실함 지금은 다 좋은데 ㅎㅎ\n",
      "요즘 경찰 방송쪽에 돈 엄청 쏟는가보네 무슨 경찰 소재 드라마가 이리 막 쏟아지냐 \n",
      "유승호가 아무리 쪄도 악플 단 새끼 니보단 훨씬 잘생겼다\n",
      "유승호 넘조타 하악 \n",
      " 대의 한국 남자들은 유승호에게 관심도 없거니와 악플 다는 것조차 귀찮아 악플을 누가 달았겠어 그분들이지 쿵쾅쿵쾅\n",
      "진짜 제목만봐도 코웃음난다 유승호가 얼굴로 까이다닠ㅋㅋㅋ\n",
      "유승호 ㅐ대 배우중에 외모 탑급인데ㅋㅋㅋ\n",
      "ㅋㅋㅋ 유승호는 건들지말자\n",
      "한녀들 왜저래 적당히좀 해라\n",
      "이놈의 악플러드 전부 벌금형이상으로 형량을높여야 없어지려나 \n",
      "유승호한테 외모지적이라니 ㅋㅋㅋ ㅁㅊㄴ\n"
     ]
    }
   ],
   "source": [
    "df_new.comment = normalized_text\n",
    "for sentence in df_new['comment']:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "def train(comments, model_result):\n",
    "    comment_data = pd.DataFrame(comments)\n",
    "    comment_data.columns = ['comment']\n",
    "    in_result = np.insert(model_result, 0, 0)\n",
    "    de_result = np.delete(in_result,0)\n",
    "    de_data = pd.DataFrame(de_result)\n",
    "    de_data.columns = ['label']\n",
    "    df_new = pd.concat([de_data, comment_data], axis = 1)\n",
    "    X_data = df_new['comment']\n",
    "    y_data = df_new['label']\n",
    "    normalized_text = []\n",
    "    for string in X_data.tolist():\n",
    "        try:\n",
    "            tokens = re.sub(r\"[^ㄱ-ㅎㅏ-ㅣ가-힣]+\", \" \", string.lower())\n",
    "        except Exception as e:\n",
    "            break\n",
    "    normalized_text.append(tokens)\n",
    "    #df_new.comment = normalized_text\n",
    "    okt = Okt()\n",
    "    X_token=[]\n",
    "    for sentence in df_new['comment']:\n",
    "        temp_X = []\n",
    "        temp_X = okt.morphs(sentence, stem=True) # 토큰화\n",
    "        X_token.append(temp_X)\n",
    "    max_words = 10000\n",
    "    tokenizer = Tokenizer(num_words = max_words) # 상위 35,000개의 단어만 보존\n",
    "    tokenizer.fit_on_texts(X_token) \n",
    "    X_token = tokenizer.texts_to_sequences(X_token)\n",
    "    word_to_index = tokenizer.word_index\n",
    "    vocab_size = len(word_to_index) + 1\n",
    "    max_len = 124\n",
    "    X_data = pad_sequences(X_token, maxlen=max_len)\n",
    "    y_data = np.array(y_data).reshape(-1, 1)\n",
    "    model = load_model('model8n.h5')\n",
    "    history = model.fit(X_data, y_data, epochs=5, batch_size=32)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20 samples\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 2s 116ms/sample - loss: 0.1494 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 14ms/sample - loss: 0.1378 - acc: 0.9500\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0746 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 11ms/sample - loss: 0.0213 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 8ms/sample - loss: 0.0155 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c35821d848>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(s, model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(url):\n",
    "    source_code_from_URL = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(source_code_from_URL, 'lxml', from_encoding='utf-8')\n",
    "    text = ''\n",
    "    for item in soup.find_all('div', id='articeBody'):\n",
    "        text = text + str(item.find_all(text=True))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt=get_text('https://entertain.naver.com/read?oid=109&aid=0004166734')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    cleaned_text = re.sub(r\"[^ㄱ-ㅎㅏ-ㅣ가-힣\\.]+\", \" \", text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = clean_text(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(url):\n",
    "    source_code_from_URL = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(source_code_from_URL, 'lxml', from_encoding='utf-8')\n",
    "    text = soup.select_one('h2.end_tit')\n",
    "    text_r = text.get_text()\n",
    "    return text_r\n",
    "title = get_title('https://entertain.naver.com/read?oid=109&aid=0004166734')\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from krwordrank.sentence import summarize_with_sentences\n",
    "def keyword_sentence(url):#키워드 문장 추출\n",
    "    m_text = get_text('https://entertain.naver.com/read?oid=109&aid=0004166734')\n",
    "    r_text = clean_text(m_text)\n",
    "    data = r_text.split('.')\n",
    "    keywords, sents = summarize_with_sentences(data, num_keywords=11, num_keysents=10)\n",
    "    keyword = list(keywords.keys())\n",
    "    return keyword[0], sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword, sents = keyword_sentence(clean)\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(current_word, n): # 모델, 토크나이저, 현재 단어, 반복할 횟수\n",
    "    global keyword\n",
    "    model = load_model('model_create.h5')\n",
    "    max_words = 35000\n",
    "    t = Tokenizer(num_words = max_words)\n",
    "    init_word = current_word \n",
    "    sentence = ''\n",
    "    for _ in range(n): # n번 반복\n",
    "        encoded = t.texts_to_sequences([current_word])[0] # 현재 단어에 대한 정수 인코딩\n",
    "        encoded = pad_sequences([encoded], maxlen=30, padding='pre') # 데이터에 대한 패딩\n",
    "        result = model.predict_classes(encoded, verbose=0)\n",
    "    # 입력한 X(현재 단어)에 대해서 y를 예측하고 y(예측한 단어)를 result에 저장.\n",
    "        for k, index in t.word_index.items(): \n",
    "            if index == result: # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면\n",
    "                break # 해당 단어가 예측 단어이므로 break\n",
    "        current_word = current_word + ' '  + k # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
    "        sentence = sentence + ' ' + k # 예측 단어를 문장에 저장\n",
    "    # for문이므로 이 행동을 다시 반복\n",
    "    sentence = init_word + sentence\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "def clean_sentence(word):\n",
    "    global keyword\n",
    "    max_words = 35000\n",
    "    clean_sen = []\n",
    "    for i in range(0,10):\n",
    "        sentence = sentence_generation(word, i)\n",
    "        clean_sen.append(sentence)\n",
    "        i += 1\n",
    "    return clean_sen[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_sentence(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(model, t, current_word, n): # 모델, 토크나이저, 현재 단어, 반복할 횟수\n",
    "    global word\n",
    "    init_word = current_word # 처음 들어온 단어도 마지막에 같이 출력하기위해 저장\n",
    "    sentence = ''\n",
    "    for _ in range(n): # n번 반복\n",
    "        encoded = t.texts_to_sequences([current_word])[0] # 현재 단어에 대한 정수 인코딩\n",
    "        encoded = pad_sequences([encoded], maxlen=30, padding='pre') # 데이터에 대한 패딩\n",
    "        result = model.predict_classes(encoded, verbose=0)# 입력한 X(현재 단어)에 대해서 y를 예측하고 y(예측한 단어)를 result에 저장.\n",
    "        for word, index in t.word_index.items(): \n",
    "            if index == result: # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면\n",
    "                break # 해당 단어가 예측 단어이므로 break\n",
    "        current_word = current_word + ' '  + word # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
    "        sentence = sentence + ' ' + word # 예측 단어를 문장에 저장\n",
    "    # for문이므로 이 행동을 다시 반복\n",
    "    sentence = init_word + sentence\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(word):\n",
    "    clean_sen = []\n",
    "    model = load_model('model_create.h5')\n",
    "    max_words = 35000\n",
    "    t = Tokenizer(num_words = max_words)\n",
    "    for i in range(0,10):\n",
    "        sentence = sentence_generation(model, t, word, i)\n",
    "        clean_sen.append(sentence)\n",
    "        i += 1\n",
    "    return clean_sen[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_sentence(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
