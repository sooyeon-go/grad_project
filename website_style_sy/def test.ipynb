{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common import exceptions\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://news.nate.com/view/20200409n03395?mid=n1008'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "def get_text(url):\n",
    "    source_code_from_URL = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(source_code_from_URL, 'lxml', from_encoding='utf-8')\n",
    "    text = ''\n",
    "    for item in soup.find_all('div', id='realArtcContents'):\n",
    "        text = text + str(item.find_all(text=True))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    cleaned_text = re.sub(r\"[^ㄱ-ㅎㅏ-ㅣ가-힣\\.]+\", \" \", str(text))\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(url):\n",
    "    source_code_from_URL = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(source_code_from_URL, 'html.parser', from_encoding='utf-8')\n",
    "    text = soup.find('h3',class_='articleSubecjt')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = \"C:\\\\Users\\\\user\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comment(url):\n",
    "    driver = webdriver.Chrome(wd)\n",
    "    url_nums = re.findall(\"\\d+\", url)\n",
    "    addr = 'http://comm.news.nate.com/Comment/ArticleComment/List?artc_sq='+url_nums[0]+'n'+url_nums[1] # 댓글창 주소\n",
    "    driver.get(addr)\n",
    "    pages = 2\n",
    "    try:\n",
    "        for i in range(5):\n",
    "            WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR,\"body > div.commentBox.reply_hide > div:nth-child(3) > div.paging_wrap > a:nth-child(\"+str(pages)+\")\"))).click()\n",
    "            time.sleep(2)\n",
    "            print(pages, end=\" \")\n",
    "            pages+=1\n",
    "    except exceptions.ElementNotVisibleException as e: # 페이지 끝\n",
    "        pass\n",
    "    except Exception as e: # 다른 예외 발생시 확인\n",
    "        print(e)\n",
    "    html = driver.page_source\n",
    "    dom = BeautifulSoup(html, \"lxml\")\n",
    "    # 댓글이 들어있는 페이지 전체 크롤링\n",
    "    comments_raw = dom.find_all('dd',{'class':'usertxt'})\n",
    "    # 댓글의 text만 뽑는다.\n",
    "    comments = [comment.text.strip() for comment in comments_raw]\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3 4 5 6 "
     ]
    },
    {
     "data": {
      "text/plain": [
       "'미래에는 결혼 안하고 그냥 몇개월 몇년단위로 동거만 하는 계약도 나올 듯'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = comment(url)\n",
    "s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 엑스포츠뉴스 김미지 기자 트로트가수 임영웅 영탁 이찬원 장민호가 결혼 계획까지 밝히는 토크로 또 한번 라디오스타 를 들썩이게 했다. 일 방송된 라디오스타 에는 오늘은 미스터트롯 특집 부로 지난주에 이어 임영웅 영탁 이찬원 장민호와 스페셜 홍진영이 함께했다. 이날 임영웅은 결혼을 하고 싶다 며 구체적인 조건을 밝혀 눈길을 끌었다. 임영웅은 연애를 최소 년 정도 하고 싶고 개월 정도 같이 살아봐야 한다고 생각한다 며 한 번 결혼하면 쭉 오래 하고 싶은 마음이 있다 고 말했다. 임영웅은 동거 이야기를 하며 머뭇거리며 눈치를 보는 모습으로 귀여운 매력을 어필했다. 들 역시 그게 현명한 것 이라며 응원했다. 반면 영탁은 라디오 인터뷰 당시 얼떨결에 비혼 선언을 했다며 주변에 자문을 해봤는데 팬들과의 의리를 지키기 위해 년은 있어야 하지 않겠냐는 답을 들었다 며 지금은 열심히 일할 것 이라고 말했다. 또 장민호를 가리키며 년은 괜찮다. 민호 형도 있으니 라고 말해 웃음을 자아냈다. 올해 나이 세인 장민호는 연관검색어가 유부남 결혼 이었다 며 미스터트롯 이 끝나고 결혼을 하고 싶은 마음이 조금씩 생기는 것 같다 고 고백했다. 대 중반인 이찬원은 어린 시절 뿔테 안경과 함께했던 과거를 떠올리며 시력이 마이너스였는데 살이 되자마자 렌즈를 했다 며 연애를 하고 싶어서 안경을 벗었다 고 말해 풋풋함을 자아냈다. . 사진 가수 조 디피 코로나 로 사망 연예계도 패닉 송혜교 솔직 고백 어릴 때부터 만난 사람 내 옆에 있어 서장훈 무슨 일이야 돌연 방송 하차 선언 제작진 당황 성폭행 혐의 김건모 억 피해 손배소 청구 반격 한채아 남편 차세찌 징역형 구형 차범근 차두리 미안 엑스포츠뉴스 무단 전재 및 재배포 금지 . . . . . . . . . . . \n"
     ]
    }
   ],
   "source": [
    "t = get_text(url)\n",
    "cl = clean_text(t)\n",
    "print(cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from krwordrank.sentence import summarize_with_sentences\n",
    "def keyword_sentence(url):#키워드 문장 추출\n",
    "    m_text = get_text(url)\n",
    "    r_text = clean_text(m_text)\n",
    "    data = r_text.split('.')\n",
    "    keywords, sents = summarize_with_sentences(data, num_keywords=1, num_keysents=1)\n",
    "    keyword = list(keywords.keys())\n",
    "    return keyword[0], sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword, sents = keyword_sentence(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'하고'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from konlpy.tag import Okt  \n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.common import exceptions\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_load(comments):\n",
    "    token_sent=[]\n",
    "    for comment in comments:\n",
    "        temp = okt.morphs(comment, stem=True)\n",
    "        token_sent.append(temp)\n",
    "        max_words = 35000\n",
    "    tokenizer = Tokenizer(num_words = max_words) # 상위 35,000개의 단어만 보존\n",
    "    tokenizer.fit_on_texts(token_sent) \n",
    "    token_sent = tokenizer.texts_to_sequences(token_sent)\n",
    "    word_to_index = tokenizer.word_index\n",
    "    vocab_size = len(word_to_index)+1\n",
    "    max_len = 124\n",
    "    X_data = pad_sequences(token_sent, maxlen=max_len)\n",
    "    model = load_model('model8n.h5')\n",
    "    predict = model.predict_classes(X_data)\n",
    "    #for i in range(len(X_data)):\n",
    "    #    if(predict[i] == 0):\n",
    "    #        a=0\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'미래에는 결혼 안하고 그냥 몇개월 몇년단위로 동거만 하는 계약도 나올 듯'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "동거는 필수다. 동거해야 상대를 제대로 이해하고 거를수 잇음\n"
     ]
    }
   ],
   "source": [
    "print(s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result = model_load(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n",
      "[1 0 0 0 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model_result)\n",
    "print(np.delete(model_result,1))\n",
    "model_result.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "[8, 9, 12, 14, 16, 17, 19]\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "number = []\n",
    "for i in range(1,len(model_result)):\n",
    "    if model_result[i] == 1:\n",
    "        count += 1\n",
    "        number.append(i)\n",
    "print(count)\n",
    "print(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(num):\n",
    "    count = 0\n",
    "    number = []\n",
    "    for i in range(1, len(num)):\n",
    "        if num[i] == 1:\n",
    "            count += 1\n",
    "            number.append(i)\n",
    "    return count, number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "[8, 9, 12, 14, 16, 17, 19]\n"
     ]
    }
   ],
   "source": [
    "a,b = count(model_result)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = [\"요즘 연기 정말 잘보고있어요! 항상 응원해요\",\n",
    "        \"항상 열심히 하는 모습 너무 보기 좋아요:)\",\n",
    "        \"최근 작품에서 연기 정말 많이 늘었더라고요!\",\n",
    "        \"연기가 너무 좋아서 응원해요~\",\n",
    "        \"요즘 내가 가장 좋아하는 배우 중 한 명ㅎㅎ\",\n",
    "        \"어떤 연기를 해도 보는 사람의 심금을 울리는 배우\",\n",
    "        \"요즘 얼굴 정말 좋아보여요\",\n",
    "        \"예전부터 지금까지 계속해서 응원하고 있어요:)\",\n",
    "        \"연기로는 절대 뭐라 못하는 배우\",\n",
    "        \"연기신\",\n",
    "        \"정말 얼굴 천재..그 자체\",\n",
    "        \"요즘 너무 좋아요!\",\n",
    "        \"진짜 송강호급 연기자다 연기레알 개잘함.\",\n",
    "        \"연기 너무 잘해ㅠㅠㅠㅠ\",\n",
    "        \"이번년도 연기 대상 주자!!!!!!\",\n",
    "        \"발성.발음.표정...참 몰입되는 배우님...응원합니다.\",\n",
    "        \"대상 받아야해요....\",\n",
    "        \"난 옛날부터연기잘하는거알고있었지.. \",\n",
    "        \"사랑해요!!!!!!!!!!!\",\n",
    "        \"걍 지린다.. 연기 너무 잘하시는 듯\",\n",
    "        \"진짜 연기 미쳤어.......\",\n",
    "        \"진짜 깔게 없는 연기력 .. \",\n",
    "        \"표정 연기가 너무 섬세하셔서 숨 안쉬고 보게 되는.. 응원합니다 배우님 :>\",\n",
    "        \"연기 볼 때마다 놀라요 흡입력이 진짜.. \",\n",
    "        \"진심 시상식에서 상 받아야할 신들린 연기자\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "singer = [\"미세먼지 한톨도 안먹은 목소리의 주인공 진짜.......\",\n",
    "         \"음악성은 진짜..말도 안된다고 생각한다.. \",\n",
    "         \"한국 가수 역사상 최고인 사람\",\n",
    "         \"목소리가 진짜 보물이야\",\n",
    "         \"목소리가 보석같다\",\n",
    "         \"외로움과 따뜻함을 모두 가진 가수 목소리를 듣고 있으면 내면의 외로움이 느껴지고 그게 안쓰러워 다가가면 그가 가진 따스함에 오히려 위로 받게 되는 나 자신을 발견하게 됨..\",\n",
    "         \"같은 시대에 태어나 이 목소리를 들을 수 있다는건 정말 해운이야\",\n",
    "         \"음색도 너무 좋지만 말하는거 보면 말도 따뜻하고 예쁘게 하는 듯\",\n",
    "         \"어떻게 사람이 이렇게 모든게 완벽하냐\",\n",
    "         \"이 사람의 노래를 들으며 내 인생의 슬픔을 치유받았다..\",\n",
    "         \"나의 사랑하는 아티스트\",\n",
    "         \"내 인생 가수\",\n",
    "         \"정말 몇 번을 들어도 소름돋는 가창력 음색\",\n",
    "         \"음색도 뭐도 다 좋지만 감성이 너무 좋다\",\n",
    "         \"먼 미래에 더 더 빛나는 뮤지션으로 재평가 될 가수\",\n",
    "         \"항상 이 목소리 유지해줘 ㅠㅠ 항상 응원해\",\n",
    "         \"당신을 보고 눈물이 나는건 당신을 위로하고 싶은 나 때문인지 당신한테 위로받고 싶은 나 때문인지\",\n",
    "         \"정말 강한 사람 같다. 내가 자식을 낳는다면 이렇게 키우고 싶어\",\n",
    "         \"감성, 보컬실력, 섬세한 삼박자 모두 갖춘 최고의가수\",\n",
    "         \"콘서트 한 번만 가보면 소원이 없겠다 진짜로\",\n",
    "         \"독보적인 가수\",\n",
    "         \"음원보다 라이브가 훠어어얼씬 좋은 가수\",\n",
    "         \"진짜 사기캐..사람이 어떻게 이렇게 완벽하냐\",\n",
    "         \"새삼스럽게 말하지만 노래 진짜 잘해\",\n",
    "         \"언제나 응원합니다:)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "entertain = [\"강약 조절이 능숙한 개그맨..진짜 어디서도 못구함\",\n",
    "            \"진짜 떡잎부터 도른자 ㅋㅋㅋㅋ너무 웃겨\",\n",
    "            \"코미디언 중에서 탑이다 ㅋㅋ\",\n",
    "            \"남녀 통틀어서 이런사람 드물거같아 ㅋㅋ\",\n",
    "            \"정말 박미선처럼 롱런하면 좋겠다\",\n",
    "            \"입담이나 재치가 진짜 너무 사기캐..\",\n",
    "            \"막 힘들어간 억지 개그 없이 말하나 행동 하나하나 너무 웃겨서 좋아요 ㅋㅋㅋㅋ\",\n",
    "            \"개좋아 진짜로 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ\",\n",
    "            \"내 호적메이트면 좋겠다 너무 좋음ㅋㅋㅋㅋ\",\n",
    "            \"개그가 기분 나쁘지 않고 깔끔함\",\n",
    "            \"이번년도에 대상 받자!!!!!\",\n",
    "            \"진짜 너무 재미있어 ㅋㅋㅋㅋ\",\n",
    "            \"진짜 장난 아니게 웃기고 센스 쩔고 사랑스러운데 올해 상 휩쓸고 다니자\",\n",
    "            \"찜찜하고 강제로 웃게 만드는게 아니라 진짜 자연스럽고 유머스러움에 감탄하며 건강한 웃음을 재창조해낸ㄴ 이 시대 최고\",\n",
    "            \"진짜 말하는 것부터 하는 액션까지 전부 따 뼛속부터 개그맨 ㅋㅋ\",\n",
    "            \"성격 진짜 좋아보이더라\",\n",
    "            \"말빨로 웃기는 연옌 드문데 진짜 드문케이스.\",\n",
    "            \"센스있게 웃기기 쉽지 않은데 진짜 센스가 장난 아니고 성격도 진실되어보임\",\n",
    "            \"내 롤모델이다 진짜로 ㅋㅋㅋㅋㅋ\",\n",
    "            \"너무 특색있고 오바하지 않는데도 웃겨 ㅋㅋㅋ\",\n",
    "            \"진짜 타고나기를 개그맨이다..\",\n",
    "            \"개그 진짜 내 취향임\",\n",
    "            \"너무 열심히 하고 기본 인성이 착한듯\",\n",
    "            \"보는 사람이 기분 하나도 나쁘지 않고 센스있게 웃겨서 좋음 ㅠㅠㅠㅠㅠㅠㅠ\",\n",
    "            \"저렇게 웃기고 재치있고 센스있고 귀여운 사람이 세상에 또 어딨어 ㅋㅋ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "virtue = [\"진짜 클라스 보소 역시..\",\n",
    "         \"갓갓\",\n",
    "         \"이게 뭐라고 눈이 촉촉히 젖어오네요\",\n",
    "         \"머리로는 이렇게 해야한다, 이런행동을 해야한다고 생각해도 행동으로 옮기긴 정말 힘들텐데..대단하다\",\n",
    "         \"이런 선행이 더 많아지면 좋겠다\",\n",
    "         \"인성짱짱이다\",\n",
    "         \"진짜 착하다...\",\n",
    "         \"존경스럽다\",\n",
    "         \"진짜 멋있는거같다 ㅠㅠ\",\n",
    "         \"사람이 왜 칭찬받고 하는지 보면 다 이유가 있는데 정말 착하다\",\n",
    "         \"당신은 도덕책..\",\n",
    "         \"참 멋있는 사람이네요.\",\n",
    "         \"이런일 하는게 쉬운 일은 아닐텐데 진짜 멋있다\",\n",
    "         \"세상은 아직 살만하다는걸 느낀다\",\n",
    "         \"참 대단하네요 마인드가..존경스럽습니다\",\n",
    "         \"세상이 더럽다고 느끼고 좌절할 때 쯤 이런 기사를 보게돼서 다행이다\",\n",
    "         \"굉장히 교양있어보인다..\",\n",
    "         \"크 멋있어라 적게 일하고 돈 많이 벌길~\",\n",
    "         \"가정 교육 제대로 받았네\",\n",
    "         \"앞으로 좋은 꽃길만 걷길...\",\n",
    "         \"아름다워서 눈물이 날려하네요  참 착해요\",\n",
    "         \"천사가 여기있네\",\n",
    "         \"이런 사람보고 성인이라고 하는거지\",\n",
    "         \"보면 볼수록 정말 괜찮은 사람이라는게 느껴진다\",\n",
    "         \"연예인이 아니라 인간대 인간으로 보아도 괜찮은 사람같다\",\n",
    "         \"크 클라스 보소\",\n",
    "         \"참 좋은 사람인 것 같아\",\n",
    "         \"사람을 행복하게 하는 비타민 같은 존재..항상 좋은 일만 있으면 좋겠다\",\n",
    "         \"인성 진자 최고인거같다\",\n",
    "         \"인성킹\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_c = [\"연기\", \"배우\", \"작품\", \"차기작\", \"영화\", \"드라마\", \"시청\"]\n",
    "singer_c = [\"음색\", \"콘서트\", \"무대\", \"노래\", \"가수\", \"그룹\", \"아이돌\", \"걸그룹\", \"춤\", \"댄스\", \"작사\", \"작곡\"]\n",
    "entertain_c = [\"예능\", \"개그맨\", \"개그우먼\",\"유승호\"]\n",
    "virtue_c = [\"기부\", \"선행\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "\n",
    "def select(text, number):#기사 내용 중 단어 선별하기\n",
    "    lines = []\n",
    "    line2 = []\n",
    "    for word in text:\n",
    "        lines = str.split(text,\".\")\n",
    "    for each_line in lines:\n",
    "        result = []\n",
    "        if each_line.find(\"기부\") > 0:\n",
    "            result = random.sample(virtue, number)\n",
    "            key = \"기부\"\n",
    "            break\n",
    "        elif each_line.find(\"선행\") > 0:\n",
    "            result = random.sample(virtue, number)\n",
    "            key = \"선행\"\n",
    "            break\n",
    "        elif each_line.find(\"연기\") > 0:\n",
    "            result = random.sample(actor, number)\n",
    "            key = \"연기\"\n",
    "            break\n",
    "        elif each_line.find(\"배우\") > 0:\n",
    "            result = random.sample(actor, number)\n",
    "            key = \"배우\"\n",
    "            break \n",
    "        elif each_line.find(\"작품\") > 0:\n",
    "            result = random.sample(actor, number)\n",
    "            key = \"작품\"\n",
    "            break\n",
    "        elif each_line.find(\"차기작\") > 0:\n",
    "            result = random.sample(actor, number)\n",
    "            key = \"차기작\"\n",
    "            break\n",
    "        elif each_line.find(\"영화\") > 0:\n",
    "            result = random.sample(actor, number)\n",
    "            key = \"영화\"\n",
    "            break\n",
    "        elif each_line.find(\"드라마\") > 0:\n",
    "            result = random.sample(actor, number)\n",
    "            key = \"드라마\"\n",
    "            break\n",
    "        elif each_line.find(\"시청\") > 0:\n",
    "            result = random.sample(actor, number)\n",
    "            key = \"시청\"\n",
    "            break\n",
    "        elif each_line.find(\"음색\") > 0:\n",
    "            result = random.sample(singer, number)\n",
    "            key = \"음색\"\n",
    "            break\n",
    "        elif each_line.find(\"콘서트\") > 0:\n",
    "            result = random.sample(singer, number)\n",
    "            key = \"콘서트\"\n",
    "            break\n",
    "        elif each_line.find(\"무대\") > 0:\n",
    "            result = random.sample(singer, number)\n",
    "            key = \"무대\"\n",
    "            break\n",
    "        elif each_line.find(\"노래\") > 0:\n",
    "            result = random.sample(singer, number)\n",
    "            key = \"노래\"\n",
    "            break\n",
    "        elif each_line.find(\"가수\") > 0:\n",
    "            result = random.sample(singer, number)\n",
    "            key = \"가수\"\n",
    "            break\n",
    "        elif each_line.find(\"그룹\") > 0:\n",
    "            result = random.sample(singer, number)\n",
    "            key = \"그룹\"\n",
    "            break\n",
    "        elif each_line.find(\"아이돌\") > 0:\n",
    "            result = random.sample(singer, number)\n",
    "            key = \"아이돌\"\n",
    "            break\n",
    "        elif each_line.find(\"걸그룹\") > 0:\n",
    "            result = random.sample(singer, number)\n",
    "            key = \"걸그룹\"\n",
    "            break\n",
    "        elif each_line.find(\"춤\") > 0:\n",
    "            result = random.sample(singer, number)\n",
    "            key = \"춤\"\n",
    "            break\n",
    "        elif each_line.find(\"댄스\") > 0:\n",
    "            result = random.sample(singer, number)\n",
    "            key = \"댄스\"\n",
    "            break\n",
    "        elif each_line.find(\"예능\") > 0:\n",
    "            result = random.sample(entertain, number)\n",
    "            key = \"예능\"\n",
    "            break\n",
    "        elif each_line.find(\"개그맨\") > 0:\n",
    "            result = random.sample(entertain, number)\n",
    "            key = \"개그맨\"\n",
    "            break\n",
    "        elif each_line.find(\"개그우먼\") > 0:\n",
    "            result = random.sample(entertain, number)\n",
    "            key = \"개그우먼\"\n",
    "            break\n",
    "        elif each_line.find(\"예능\") > 0:\n",
    "            result = random.sample(entertain, number)\n",
    "            key = \"예능\"\n",
    "            break\n",
    "        else:\n",
    "            break\n",
    "    return key, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'미세먼지 한톨도 안먹은 목소리의 주인공 진짜.......'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key, text = select(cl, a)\n",
    "text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'가수'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['미세먼지 한톨도 안먹은 목소리의 주인공 진짜.......',\n",
       " '당신을 보고 눈물이 나는건 당신을 위로하고 싶은 나 때문인지 당신한테 위로받고 싶은 나 때문인지',\n",
       " '음악성은 진짜..말도 안된다고 생각한다.. ',\n",
       " '외로움과 따뜻함을 모두 가진 가수 목소리를 듣고 있으면 내면의 외로움이 느껴지고 그게 안쓰러워 다가가면 그가 가진 따스함에 오히려 위로 받게 되는 나 자신을 발견하게 됨..',\n",
       " '감성, 보컬실력, 섬세한 삼박자 모두 갖춘 최고의가수',\n",
       " '정말 몇 번을 들어도 소름돋는 가창력 음색',\n",
       " '정말 강한 사람 같다. 내가 자식을 낳는다면 이렇게 키우고 싶어']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete(result, number):\n",
    "    new = np.delete(result, number)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def de_comment(comments, number):\n",
    "    new = np.delete(comments, number)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stra = de_comment(s, b)\n",
    "stra_num = delete(model_result, b)\n",
    "print(stra)\n",
    "print(stra_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count2(num): #count는 악플 개수, number은 악플 위치\n",
    "    number = []\n",
    "    for i in range(1, len(num)):\n",
    "        if num[i] == 0:\n",
    "            number.append(i)\n",
    "    return number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def de_comment2(comments, number):\n",
    "    new = np.delete(comments, number)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = count2(model_result)\n",
    "new = de_comment(s, c)\n",
    "print(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "comment_data = pd.DataFrame(s)\n",
    "comment_data.columns = ['comment']\n",
    "comment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_result = np.insert(model_result, 0, 0)\n",
    "de_result = np.delete(in_result,0)\n",
    "print(de_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_data = pd.DataFrame(de_result)\n",
    "de_data.columns = ['label']\n",
    "de_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.concat([de_data, comment_data], axis = 1)\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = df_new['comment']\n",
    "y_data = df_new['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_text = []\n",
    "for string in X_data.tolist():\n",
    "    try:\n",
    "        tokens = re.sub(r\"[^ㄱ-ㅎㅏ-ㅣ가-힣]+\", \" \", string.lower())\n",
    "    except Exception as e:\n",
    "        print(string)\n",
    "        break\n",
    "    normalized_text.append(tokens)\n",
    "print(normalized_text[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_new.comment = normalized_text\n",
    "for sentence in df_new['comment']:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "def train(comments, model_result):\n",
    "    comment_data = pd.DataFrame(comments)\n",
    "    comment_data.columns = ['comment']\n",
    "    in_result = np.insert(model_result, 0, 0)\n",
    "    de_result = np.delete(in_result,0)\n",
    "    de_data = pd.DataFrame(de_result)\n",
    "    de_data.columns = ['label']\n",
    "    df_new = pd.concat([de_data, comment_data], axis = 1)\n",
    "    X_data = df_new['comment']\n",
    "    y_data = df_new['label']\n",
    "    normalized_text = []\n",
    "    for string in X_data.tolist():\n",
    "        try:\n",
    "            tokens = re.sub(r\"[^ㄱ-ㅎㅏ-ㅣ가-힣]+\", \" \", string.lower())\n",
    "        except Exception as e:\n",
    "            break\n",
    "    normalized_text.append(tokens)\n",
    "    #df_new.comment = normalized_text\n",
    "    okt = Okt()\n",
    "    X_token=[]\n",
    "    for sentence in df_new['comment']:\n",
    "        temp_X = []\n",
    "        temp_X = okt.morphs(sentence, stem=True) # 토큰화\n",
    "        X_token.append(temp_X)\n",
    "    max_words = 10000\n",
    "    tokenizer = Tokenizer(num_words = max_words) # 상위 35,000개의 단어만 보존\n",
    "    tokenizer.fit_on_texts(X_token) \n",
    "    X_token = tokenizer.texts_to_sequences(X_token)\n",
    "    word_to_index = tokenizer.word_index\n",
    "    vocab_size = len(word_to_index) + 1\n",
    "    max_len = 124\n",
    "    X_data = pad_sequences(X_token, maxlen=max_len)\n",
    "    y_data = np.array(y_data).reshape(-1, 1)\n",
    "    model = load_model('model8n.h5')\n",
    "    history = model.fit(X_data, y_data, epochs=5, batch_size=32)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(s, model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(url):\n",
    "    source_code_from_URL = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(source_code_from_URL, 'lxml', from_encoding='utf-8')\n",
    "    text = ''\n",
    "    for item in soup.find_all('div', id='articeBody'):\n",
    "        text = text + str(item.find_all(text=True))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt=get_text('https://entertain.naver.com/read?oid=109&aid=0004166734')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    cleaned_text = re.sub(r\"[^ㄱ-ㅎㅏ-ㅣ가-힣\\.]+\", \" \", text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = clean_text(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(url):\n",
    "    source_code_from_URL = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(source_code_from_URL, 'lxml', from_encoding='utf-8')\n",
    "    text = soup.select_one('h2.end_tit')\n",
    "    text_r = text.get_text()\n",
    "    return text_r\n",
    "title = get_title('https://entertain.naver.com/read?oid=109&aid=0004166734')\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from krwordrank.sentence import summarize_with_sentences\n",
    "def keyword_sentence(url):#키워드 문장 추출\n",
    "    m_text = get_text('https://entertain.naver.com/read?oid=109&aid=0004166734')\n",
    "    r_text = clean_text(m_text)\n",
    "    data = r_text.split('.')\n",
    "    keywords, sents = summarize_with_sentences(data, num_keywords=11, num_keysents=10)\n",
    "    keyword = list(keywords.keys())\n",
    "    return keyword[0], sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword, sents = keyword_sentence(clean)\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(current_word, n): # 모델, 토크나이저, 현재 단어, 반복할 횟수\n",
    "    global keyword\n",
    "    model = load_model('model_create.h5')\n",
    "    max_words = 35000\n",
    "    t = Tokenizer(num_words = max_words)\n",
    "    init_word = current_word \n",
    "    sentence = ''\n",
    "    for _ in range(n): # n번 반복\n",
    "        encoded = t.texts_to_sequences([current_word])[0] # 현재 단어에 대한 정수 인코딩\n",
    "        encoded = pad_sequences([encoded], maxlen=30, padding='pre') # 데이터에 대한 패딩\n",
    "        result = model.predict_classes(encoded, verbose=0)\n",
    "    # 입력한 X(현재 단어)에 대해서 y를 예측하고 y(예측한 단어)를 result에 저장.\n",
    "        for k, index in t.word_index.items(): \n",
    "            if index == result: # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면\n",
    "                break # 해당 단어가 예측 단어이므로 break\n",
    "        current_word = current_word + ' '  + k # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
    "        sentence = sentence + ' ' + k # 예측 단어를 문장에 저장\n",
    "    # for문이므로 이 행동을 다시 반복\n",
    "    sentence = init_word + sentence\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "def clean_sentence(word):\n",
    "    global keyword\n",
    "    max_words = 35000\n",
    "    clean_sen = []\n",
    "    for i in range(0,10):\n",
    "        sentence = sentence_generation(word, i)\n",
    "        clean_sen.append(sentence)\n",
    "        i += 1\n",
    "    return clean_sen[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_sentence(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(model, t, current_word, n): # 모델, 토크나이저, 현재 단어, 반복할 횟수\n",
    "    global word\n",
    "    init_word = current_word # 처음 들어온 단어도 마지막에 같이 출력하기위해 저장\n",
    "    sentence = ''\n",
    "    for _ in range(n): # n번 반복\n",
    "        encoded = t.texts_to_sequences([current_word])[0] # 현재 단어에 대한 정수 인코딩\n",
    "        encoded = pad_sequences([encoded], maxlen=30, padding='pre') # 데이터에 대한 패딩\n",
    "        result = model.predict_classes(encoded, verbose=0)# 입력한 X(현재 단어)에 대해서 y를 예측하고 y(예측한 단어)를 result에 저장.\n",
    "        for word, index in t.word_index.items(): \n",
    "            if index == result: # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면\n",
    "                break # 해당 단어가 예측 단어이므로 break\n",
    "        current_word = current_word + ' '  + word # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
    "        sentence = sentence + ' ' + word # 예측 단어를 문장에 저장\n",
    "    # for문이므로 이 행동을 다시 반복\n",
    "    sentence = init_word + sentence\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(word):\n",
    "    clean_sen = []\n",
    "    model = load_model('model_create.h5')\n",
    "    max_words = 35000\n",
    "    t = Tokenizer(num_words = max_words)\n",
    "    for i in range(0,10):\n",
    "        sentence = sentence_generation(model, t, word, i)\n",
    "        clean_sen.append(sentence)\n",
    "        i += 1\n",
    "    return clean_sen[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_sentence(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
